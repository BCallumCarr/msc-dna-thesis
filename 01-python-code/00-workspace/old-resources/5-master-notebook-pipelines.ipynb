{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "\n",
    "* Decide on viewcount threshold to eliminate views\n",
    "* Get feature columns working\n",
    "* Build an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Welcome to my PySpark analysis of some StackExchange Data\"\\n'\n"
     ]
    }
   ],
   "source": [
    "## testing printing output from console\n",
    "import subprocess\n",
    "cmd = [ 'echo', '\"Welcome to my PySpark analysis of some StackExchange Data\"' ]\n",
    "output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spark UI is available at: http://192.168.0.26:4040/ and the defaultParallelism is 4\n"
     ]
    }
   ],
   "source": [
    "%run -i '1-load-pyspark.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:34:38.746175\n",
      "------------------------\n",
      "english\n",
      "------------------------\n",
      "root\n",
      " |-- _Body: string (nullable = true)\n",
      " |-- _Title: string (nullable = true)\n",
      " |-- _ViewCount: long (nullable = true)\n",
      " |-- _Score: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------+------+\n",
      "|               _Body|              _Title|_ViewCount|_Score|\n",
      "+--------------------+--------------------+----------+------+\n",
      "|<p>How do I know ...|What is the diffe...|     18413|    35|\n",
      "|<p>When you want ...|Should I use a se...|    106724|    52|\n",
      "|<blockquote>\n",
      "  <p...|What does Maugham...|      1131|    11|\n",
      "+--------------------+--------------------+----------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "------------------------\n",
      "math\n",
      "------------------------\n",
      "root\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- ViewCount: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "|                Body|               Title|ViewCount|Score|__index_level_0__|\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "|<p>Can someone ex...|What Does it Real...|     7879|  144|                0|\n",
      "|<p><a href=\"http:...|List of interesti...|    63919|  102|                1|\n",
      "|<p>I have read a ...|How can you prove...|    11354|   49|                3|\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "------------------------\n",
      "rus_stackoverflow\n",
      "------------------------\n",
      "root\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- ViewCount: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "|                Body|               Title|ViewCount|Score|__index_level_0__|\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "|<p>Нужен простейш...|Как из скрипта на...|    10786|   38|                0|\n",
      "|<p>Например, имее...|Как сохранить и в...|     3758|    9|                2|\n",
      "|<p>Какая команда ...|Как найти файл по...|    14026|    7|                4|\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "------------------------\n",
      "stackoverflow\n",
      "------------------------\n",
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- view_count: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------+-----+-----------------+\n",
      "|                body|               title|view_count|score|__index_level_0__|\n",
      "+--------------------+--------------------+----------+-----+-----------------+\n",
      "|<p>I'm converting...|Inherit a common ...|      6183|    6|                0|\n",
      "|<p>I have the fol...|Firefox onkeypres...|      5934|    2|                1|\n",
      "|<p>I would like t...|Bundle third part...|        31|    1|                2|\n",
      "+--------------------+--------------------+----------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "------------------------\n",
      "superuser\n",
      "------------------------\n",
      "root\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- ViewCount: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "|                Body|               Title|ViewCount|Score|__index_level_0__|\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "|<p>A Vista virtua...|Why does the /win...|   106189|  172|                0|\n",
      "|<p>I used to reco...|How can I remove ...|     6343|    6|                1|\n",
      "|<p>What is the di...|What's the differ...|    23892|   23|                5|\n",
      "+--------------------+--------------------+---------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 26.9 ms, sys: 19 ms, total: 45.9 ms\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '2-load-datasets.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "      <th>_Title</th>\n",
       "      <th>_ViewCount</th>\n",
       "      <th>_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;How do I know when to use &lt;em&gt;lay&lt;/em&gt; and ...</td>\n",
       "      <td>What is the difference between \"lay\" and \"lie\"?</td>\n",
       "      <td>18413</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;When you want to connect two closely relate...</td>\n",
       "      <td>Should I use a semicolon or a dash to connect ...</td>\n",
       "      <td>106724</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;&lt;strong&gt;Possible Duplicate:...</td>\n",
       "      <td>What does Maugham mean by \"his spaghetti were\"?</td>\n",
       "      <td>1131</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;How do you say it correctly?&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;...</td>\n",
       "      <td>\"Adult and children stories\" or \"Adults and ch...</td>\n",
       "      <td>959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;\"Proven\" and \"proved\" both seem to mean the...</td>\n",
       "      <td>What is the difference between \"proven\" and \"p...</td>\n",
       "      <td>52711</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               _Body  \\\n",
       "0  <p>How do I know when to use <em>lay</em> and ...   \n",
       "1  <p>When you want to connect two closely relate...   \n",
       "2  <blockquote>\\n  <p><strong>Possible Duplicate:...   \n",
       "3  <p>How do you say it correctly?</p>\\n\\n<ul>\\n<...   \n",
       "4  <p>\"Proven\" and \"proved\" both seem to mean the...   \n",
       "\n",
       "                                              _Title  _ViewCount  _Score  \n",
       "0    What is the difference between \"lay\" and \"lie\"?       18413      35  \n",
       "1  Should I use a semicolon or a dash to connect ...      106724      52  \n",
       "2    What does Maugham mean by \"his spaghetti were\"?        1131      11  \n",
       "3  \"Adult and children stories\" or \"Adults and ch...         959       2  \n",
       "4  What is the difference between \"proven\" and \"p...       52711      50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_spark_df(df, n=5):\n",
    "    '''\n",
    "    function to better print spark df entries\n",
    "    '''\n",
    "    display(pd.DataFrame(df.head(n), columns=df.columns))\n",
    "    \n",
    "show_spark_df(datasets['english'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:34:49.519166\n",
      "\n",
      "\u001b[1m checking columns are the right types and names \u001b[0m\n",
      "\n",
      "----- english -----\n",
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- math -----\n",
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- rus_stackoverflow -----\n",
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- stackoverflow -----\n",
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- superuser -----\n",
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "\n",
      "\u001b[1m checking that there are no nans \u001b[0m\n",
      "\n",
      "----- english -----\n",
      "+----+-----+---------+-----+----------+\n",
      "|body|title|viewcount|score|clean_body|\n",
      "+----+-----+---------+-----+----------+\n",
      "|   0|    0|        0|    0|         0|\n",
      "+----+-----+---------+-----+----------+\n",
      "\n",
      "----- math -----\n",
      "+----+-----+---------+-----+----------+\n",
      "|body|title|viewcount|score|clean_body|\n",
      "+----+-----+---------+-----+----------+\n",
      "|   0|    0|        0|    0|         0|\n",
      "+----+-----+---------+-----+----------+\n",
      "\n",
      "----- rus_stackoverflow -----\n",
      "+----+-----+---------+-----+----------+\n",
      "|body|title|viewcount|score|clean_body|\n",
      "+----+-----+---------+-----+----------+\n",
      "|   0|    0|        0|    0|         0|\n",
      "+----+-----+---------+-----+----------+\n",
      "\n",
      "----- stackoverflow -----\n",
      "+----+-----+---------+-----+----------+\n",
      "|body|title|viewcount|score|clean_body|\n",
      "+----+-----+---------+-----+----------+\n",
      "|   0|    0|        0|    0|         0|\n",
      "+----+-----+---------+-----+----------+\n",
      "\n",
      "----- superuser -----\n",
      "+----+-----+---------+-----+----------+\n",
      "|body|title|viewcount|score|clean_body|\n",
      "+----+-----+---------+-----+----------+\n",
      "|   0|    0|        0|    0|         0|\n",
      "+----+-----+---------+-----+----------+\n",
      "\n",
      "CPU times: user 114 ms, sys: 33.4 ms, total: 147 ms\n",
      "Wall time: 56.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '3-clean-datasets.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:35:46.018074\n",
      "CPU times: user 45.8 ms, sys: 14 ms, total: 59.8 ms\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '4-eda.py'\n",
    "\n",
    "#NB TO DO: Find threshold to delete low views to make sure users that can vote have seen the question\n",
    "\n",
    "vc_thresh_data = {}\n",
    "\n",
    "## finding means of viewcounts across fora\n",
    "\n",
    "for i in data_array:\n",
    "    vc_thresh_data[i] = datasets[i].select(\"viewcount\").rdd.flatMap(lambda x: x).mean()\n",
    "\n",
    "vc_thresh_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Ravi Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:36:03.794926\n",
      "\n",
      "The average value of \u001b[1menglish\u001b[0m y_ravi is 0.0037778\n",
      "\n",
      "\n",
      "The average value of \u001b[1mmath\u001b[0m y_ravi is 0.0121854\n",
      "\n",
      "\n",
      "The average value of \u001b[1mrus_stackoverflow\u001b[0m y_ravi is 0.006857\n",
      "\n",
      "\n",
      "The average value of \u001b[1mstackoverflow\u001b[0m y_ravi is 0.002148\n",
      "\n",
      "\n",
      "The average value of \u001b[1msuperuser\u001b[0m y_ravi is 0.0027184\n",
      "\n",
      "CPU times: user 189 ms, sys: 56.7 ms, total: 246 ms\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '5-define-target.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>score</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>y_ravi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I'm trying to install flux on my Lubuntu 15...</td>\n",
       "      <td>Fail to install python-pexpect and python-gobj...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>I'm trying to install flux on my Lubuntu 15.1...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I am trying to connect mysql client to gcp ...</td>\n",
       "      <td>Error while Connecting mysql client to GCP Clo...</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "      <td>I am trying to connect mysql client to gcp cl...</td>\n",
       "      <td>-0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;is such app available on andriod that get w...</td>\n",
       "      <td>Win10 Alerts/Notification/Errors Pushed notifi...</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "      <td>is such app available on andriod that get win...</td>\n",
       "      <td>-0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  <p>I'm trying to install flux on my Lubuntu 15...   \n",
       "0  <p>I am trying to connect mysql client to gcp ...   \n",
       "1  <p>is such app available on andriod that get w...   \n",
       "\n",
       "                                               title  viewcount  score  \\\n",
       "0  Fail to install python-pexpect and python-gobj...          4      2   \n",
       "0  Error while Connecting mysql client to GCP Clo...          7     -3   \n",
       "1  Win10 Alerts/Notification/Errors Pushed notifi...          7     -3   \n",
       "\n",
       "                                          clean_body    y_ravi  \n",
       "0   I'm trying to install flux on my Lubuntu 15.1...  0.500000  \n",
       "0   I am trying to connect mysql client to gcp cl... -0.428571  \n",
       "1   is such app available on andriod that get win... -0.428571  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_worst_qs['superuser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silly Mean and Median Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array, lit, struct\n",
    "\n",
    "## create median and mean dictionaries\n",
    "y_ravi_medians = {}\n",
    "y_ravi_means = {}\n",
    "\n",
    "## create constant median and mean columns for evaluation baseline\n",
    "for i in data_array:\n",
    "    y_ravi_medians[i] = datasets[i].approxQuantile('y_ravi', [0.5], 0.25)[0]\n",
    "    y_ravi_means[i] = datasets[i].select('y_ravi').rdd.flatMap(lambda x: x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[1menglish\u001b[0m's median model is 0.011407298175493769\n",
      "The root-mean-square error of \u001b[1mmath\u001b[0m's median model is 0.020663146117843787\n",
      "The root-mean-square error of \u001b[1mrus_stackoverflow\u001b[0m's median model is 0.018388275325985484\n",
      "The root-mean-square error of \u001b[1mstackoverflow\u001b[0m's median model is 0.01428160958495254\n",
      "The root-mean-square error of \u001b[1msuperuser\u001b[0m's median model is 0.010638377607797608\n"
     ]
    }
   ],
   "source": [
    "## import rmse evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "## create baselines dictionary\n",
    "baselines = {}\n",
    "\n",
    "for i in data_array:\n",
    "\n",
    "    ## train silly median model\n",
    "    datasets[i] = datasets[i].withColumn('median_pred', lit(y_ravi_medians[i]))\n",
    "\n",
    "    ## evaluate silly median model\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"y_ravi\", predictionCol=\"median_pred\")\n",
    "    baselines[i] = evaluator.evaluate(datasets[i])\n",
    "\n",
    "    print(\"The root-mean-square error of \" + \"\\033[1m\"+i+\"\\033[0m\"+ \"'s median model is \" + str(baselines[i]))\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i] = {'silly_median': [baselines[i], 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[1menglish\u001b[0m's mean model is 0.010981530956769198\n",
      "The root-mean-square error of \u001b[1mmath\u001b[0m's mean model is 0.019399287092401008\n",
      "The root-mean-square error of \u001b[1mrus_stackoverflow\u001b[0m's mean model is 0.017635677029884285\n",
      "The root-mean-square error of \u001b[1mstackoverflow\u001b[0m's mean model is 0.014119152415741939\n",
      "The root-mean-square error of \u001b[1msuperuser\u001b[0m's mean model is 0.010293770490768595\n"
     ]
    }
   ],
   "source": [
    "for i in data_array:\n",
    "    \n",
    "    ## train silly mean model\n",
    "    datasets[i] = datasets[i].withColumn('mean_pred', lit(y_ravi_means[i]))\n",
    "\n",
    "    ## evaluate silly mean model\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"y_ravi\", predictionCol=\"mean_pred\")\n",
    "    rmse = evaluator.evaluate(datasets[i])\n",
    "\n",
    "    print(\"The root-mean-square error of \" + \"\\033[1m\"+i+\"\\033[0m\"+ \"'s mean model is \" + str(rmse))\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    imprvt = (rmse/baselines[i] - 1)*-100\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i] = {'silly_mean': [rmse, imprvt]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>silly_median</th>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silly_mean</th>\n",
       "      <td>0.011033</td>\n",
       "      <td>3.285437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1\n",
       "silly_median  0.011407  0.000000\n",
       "silly_mean    0.011033  3.285437"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(RESULTS).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewcount Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "to_vectors = VectorAssembler(inputCols=[\"viewcount\"], outputCol=\"features\")\n",
    "\n",
    "processing_pipeline = Pipeline(stages=[to_vectors])\n",
    "\n",
    "## linear regression on just viewcount\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=0.3,\n",
    "                      elasticNetParam=0.8,\n",
    "                      featuresCol=\"features\",\n",
    "                      labelCol=\"y_ravi\",\n",
    "                      predictionCol=\"viewcount_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make final pipeline\n",
    "\n",
    "\n",
    "\n",
    "final_pipeline = Pipeline(stages=[processing_pipeline, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pipeline = final_pipeline.fit(datasets['english'])\n",
    "\n",
    "show_spark_df(trained_pipeline.transform(datasets['english']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate model\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", \n",
    "                                labelCol=\"y_ravi\", predictionCol=\"viewcount_pred\")\n",
    "\n",
    "rmse = evaluator.evaluate(datasets['english'])\n",
    "\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "imprvt = (rmse/baseline - 1)*-100\n",
    "\n",
    "RESULTS['viewcount'] = [rmse, imprvt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipelines for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## garbage collector to speed up computation\n",
    "import gc\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"y_ravi\"\n",
    "indep_text_variables = [\"title\", \"clean_body\"]\n",
    "#.drop('age').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import elements from natural language toolkit\n",
    "import nltk\n",
    "#nltk.download('all') # uncomment after first run as admin check\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def get_tokens(line):\n",
    "    '''\n",
    "    Function to parse text features\n",
    "    '''\n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuations from each word\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # lemmatizing the words, see https://en.wikipedia.org/wiki/Lemmatisation\n",
    "    '''lemmatise or stem???'''\n",
    "    words = [lmtzr.lemmatize(w) for w in words]\n",
    "    # remove single letters\n",
    "    words = [word for word in words if not len(word)==1]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "## custom transformer for nltk tokenisation\n",
    "\n",
    "class NLTKWordPunctTokenizer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        super(NLTKWordPunctTokenizer, self).__init__()\n",
    "        self.stopwords = Param(self, \"stopwords\", \"\")\n",
    "        self._setDefault(stopwords=set())\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setStopwords(self, value):\n",
    "        self._paramMap[self.stopwords] = value\n",
    "        return self\n",
    "\n",
    "    def getStopwords(self):\n",
    "        return self.getOrDefault(self.stopwords)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        stopwords = self.getStopwords()\n",
    "\n",
    "        def f(s):\n",
    "            tokens = nltk.tokenize.wordpunct_tokenize(s)\n",
    "            return [t for t in tokens if t.lower() not in stopwords]\n",
    "\n",
    "        t = ArrayType(StringType())\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "\n",
    "## custom transformer to spread spares vectors into individual columns\n",
    "class VectorMLliber(Transformer):\n",
    "    \"\"\"\n",
    "    A custom Transformer which converts a column of pyspark.ml vectors to multiple pyspark.mllib vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputCol=None):\n",
    "        super(VectorMLliber, self).__init__()\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        def f(v):\n",
    "            return Vectors.sparse(v.size, v.indices, v.values)\n",
    "        \n",
    "        df = df.rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)\n",
    "\n",
    "features = {}\n",
    "feature_vec_list = {}\n",
    "for i in data_array:\n",
    "    features[i] = word_feat_list[i].select(\"features\")\n",
    "    feature_vec_list[i] = features[i].rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "    feature_vec_list[i].cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenizer_body = NLTKWordPunctTokenizer(\n",
    "    inputCol=\"clean_body\", outputCol=\"body_words\",  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokenizer_title = NLTKWordPunctTokenizer(\n",
    "    inputCol=\"title\", outputCol=\"title_words\",  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, VectorAssembler\n",
    "\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol=\"body_words\", outputCol=\"body_features\", minDF=2)\n",
    "\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol=\"title_words\", outputCol=\"title_features\", minDF=2)\n",
    "\n",
    "VectorMLliber_body = VectorMLliber(inputCol=\"body_features\")\n",
    "\n",
    "VectorMLliber_title = VectorMLliber(inputCol=\"body_title\")\n",
    "\n",
    "\n",
    "\n",
    "processing_pipeline = Pipeline(stages=[\n",
    "    nltk_tokenizer_body, \n",
    "    nltk_tokenizer_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## check that pipeline is working (WHICH IT IS NOT)\n",
    "\n",
    "data_processed = processing_pipeline.fit(datasets['english']).transform(datasets['english'])\n",
    "\n",
    "show_spark_df(data_processed)\n",
    "\n",
    "#data_processed.head(2)[0].features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_ensembler = VectorAssembler(inputCols=[\"body_features\", \"title_features\"], \n",
    "                                         outputCol=\"features\")  \n",
    "\n",
    "processing_pipeline = Pipeline(stages=[processing_pipeline, processing_ensembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=0.3,\n",
    "                      elasticNetParam=0.8,\n",
    "                      featuresCol=\"features\",\n",
    "                      labelCol=\"y_ravi\",\n",
    "                      predictionCol=\"prediction\")\n",
    "\n",
    "# fit linear regression pipeline\n",
    "pipeline = Pipeline(stages=[processing_pipeline, lr])\n",
    "trained_pipeline = pipeline.fit(datasets['english'])\n",
    "trained_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_spark_df(trained_pipeline.transform(datasets['english']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trained_pipeline\n",
    " .transform(datasets['english'])\n",
    " .select(\n",
    "    indep_text_variables + [\"prediction\"]\n",
    " )\n",
    " .write\n",
    " .parquet(\"linreg_prediction.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions = spark.read.parquet(\"linreg_prediction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.select(\"prediction\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(estimator_pipeline, 'pipeline.joblib') \n",
    "\n",
    "reloaded = load(\"pipeline.joblib\")\n",
    "\n",
    "Now we can predict directly!\n",
    "\n",
    "reloaded.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 0-master-notebook-pipelines.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
