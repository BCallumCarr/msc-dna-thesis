{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Welcome to my PySpark analysis of some StackExchange Data\"\\n'\n"
     ]
    }
   ],
   "source": [
    "## testing printing output from console\n",
    "import subprocess\n",
    "\n",
    "cmd = [ 'echo', '\"Welcome to my PySpark analysis of some StackExchange Data\"' ]\n",
    "output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc #garbage collection\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = [\n",
    "    \"buddhism\",\n",
    "    \"economics\",\n",
    "    \"fitness\",\n",
    "    \"health\",\n",
    "    \"interpersonal\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call download script - EDIT to feed in user data_array\n",
    "#!bash 0-dataset-download.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop through data_array\n",
    "#for i in data_array:\n",
    "#    !python convert-xml-to-parquet.py \"$i\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spark UI, version 2.4.3, is available at: http://192.168.0.26:4040/ and the defaultParallelism is 4\n"
     ]
    }
   ],
   "source": [
    "%run -i '1-load-pyspark.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load easyFunctions and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## easy functions\n",
    "%run -i 'load_parquet_data.py'\n",
    "%run -i 'export_parquet_data.py'\n",
    "%run -i 'show_save_results.py'\n",
    "%run -i 'show_spark_df.py'\n",
    "\n",
    "## pipeline transformers\n",
    "%run -i 'nltkWordPunctTokeniser.py'\n",
    "%run -i 'nltkSenteniser.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Initial or Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:33:36.832307\n",
      "CPU times: user 4.72 ms, sys: 2.77 ms, total: 7.49 ms\n",
      "Wall time: 4.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "datasets = load_parquet_data(data_array, kind='clean', printSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buddhism: 5801\n",
      "economics: 7870\n",
      "fitness: 8225\n",
      "health: 5617\n",
      "interpersonal: 3123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count total questions\n",
    "s = 0\n",
    "for i in data_array:\n",
    "    s = s + datasets[i].count()\n",
    "    print(f'{i}: {datasets[i].count()}')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:33:44.808520\n",
      "CPU times: user 211 µs, sys: 67 µs, total: 278 µs\n",
      "Wall time: 228 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '2-clean-datasets.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts and LDA Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:33:44.824529\n",
      "CPU times: user 725 µs, sys: 324 µs, total: 1.05 ms\n",
      "Wall time: 1.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# about 15 min with 10 iterations and params\n",
    "print(datetime.now().time())\n",
    "#%run -i '3-feat-engineering.py'\n",
    "###\n",
    "# TRY different values of alpha and rho\n",
    "# TRY different values of K\n",
    "# TRY 'em' optimizer instead of 'online'\n",
    "# alpha=0.01, rho=0.01 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:33:44.836203\n",
      "CPU times: user 372 µs, sys: 114 µs, total: 486 µs\n",
      "Wall time: 411 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#export_parquet_data(dataArray=data_array, datasetDict=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:33:44.849551\n",
      "CPU times: user 374 µs, sys: 102 µs, total: 476 µs\n",
      "Wall time: 412 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '4-final-eda.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buddhism & 0.44 \\\\\n",
      "Economics & 0.3 \\\\\n",
      "Fitness & 0.36 \\\\\n",
      "Health & 0.15 \\\\\n",
      "Interpersonal & 0.86 \\\\\n"
     ]
    }
   ],
   "source": [
    "## correlations between score and viewcount\n",
    "for i in data_array:\n",
    "    s = i.title() + ' & ' + str(round( datasets[i].stat.corr(\"score\", \"viewcount\"), 2 )) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 70 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:47:05.801994\n",
      "economics: 0.4, from 3148 test and 7870 total\n",
      "buddhism: 0.40062058265816236, from 2324 test and 5801 total\n",
      "fitness: 0.4006079027355623, from 3295 test and 8225 total\n",
      "health: 0.40092576108242833, from 2252 test and 5617 total\n",
      "interpersonal: 0.398975344220301, from 1246 test and 3123 total\n",
      "\n",
      "\n",
      "Buddhism & 3.98 & 2.07 \\\\\n",
      "Economics & 3.69 & 2.7 \\\\\n",
      "Fitness & 6.34 & 2.17 \\\\\n",
      "Health & 4.85 & 2.21 \\\\\n",
      "Interpersonal & 25.81 & 19.13 \\\\\n",
      "CPU times: user 74.2 ms, sys: 22.8 ms, total: 97 ms\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '6c-time-train-test-split-60.py'\n",
    "#%run -i '6d-rand-train-test-split-60.py'\n",
    "\n",
    "## check standard deviations of variables\n",
    "print('\\n')\n",
    "for i in data_array:\n",
    "    s = i.title() + ' & ' + str(round( pd.to_numeric(train[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )) + ' & ' + \\\n",
    "    str(round( pd.to_numeric(test[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 1729 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninteresting to see how skewed rus_stackoverflow posts are to more posts in recent years\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "interesting to see how skewed rus_stackoverflow posts are to more posts in recent years\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silly Mean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m mean\u001b[0m model is 3.44\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m mean\u001b[0m model is 3.1\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m mean\u001b[0m model is 3.56\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m mean\u001b[0m model is 2.82\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m mean\u001b[0m model is 20.93\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0silly_mean.0tr_rmse</th>\n",
       "      <th>0silly_mean.1rmse</th>\n",
       "      <th>0silly_mean.2timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.69</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>6.34</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.85</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>25.81</td>\n",
       "      <td>20.93</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0silly_mean.0tr_rmse  0silly_mean.1rmse  0silly_mean.2timet\n",
       "Buddhism                       3.98               3.44                0.44\n",
       "Economics                      3.69               3.10                0.32\n",
       "Fitness                        6.34               3.56                0.25\n",
       "Health                         4.85               2.82                0.27\n",
       "Interpersonal                 25.81              20.93                0.32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  0silly\\_mean.0tr\\_rmse &  0silly\\_mean.1rmse &  0silly\\_mean.2timet \\\\\n",
      "\\midrule\n",
      "Buddhism      &                  3.98 &               3.44 &                0.44 \\\\\n",
      "Economics     &                  3.69 &               3.10 &                0.32 \\\\\n",
      "Fitness       &                  6.34 &               3.56 &                0.25 \\\\\n",
      "Health        &                  4.85 &               2.82 &                0.27 \\\\\n",
      "Interpersonal &                 25.81 &              20.93 &                0.32 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "## choose target variable\n",
    "target = 'score'\n",
    "\n",
    "## create mean dictionaries\n",
    "y_ravi_tr_means = {}\n",
    "\n",
    "## calculate the mean of each forum, using ONLY training set\n",
    "for i in data_array:\n",
    "    y_ravi_tr_means[i] = train[i].select(target).rdd.flatMap(lambda x: x).mean()\n",
    "\n",
    "## import rmse evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "## create dictionaries for training and testing (baseline) rmse \n",
    "base = {}\n",
    "tr_rmse = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "\n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## train silly mean model by assigning training set mean for training and testing predictions\n",
    "    train[i] = train[i].withColumn('mean_pred', F.lit(y_ravi_tr_means[i]))\n",
    "    test[i] = test[i].withColumn('mean_pred', F.lit(y_ravi_tr_means[i]))\n",
    "\n",
    "    ## evaluate silly mean model, on both training and testing set\n",
    "    evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='mean_pred')\n",
    "    tr_rmse[i] = round( evaluator.evaluate(train[i]), 2)\n",
    "    base[i] = round( evaluator.evaluate(test[i]), 2)\n",
    "\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m mean\\033[0m model is {base[i]}\")\n",
    "\n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "    \n",
    "    ## store as dictionary inside RESULTS dictionary, initiating dataset name entries first\n",
    "    RESULTS[i.title()]['0silly_mean.0tr_rmse'] = tr_rmse[i]\n",
    "    RESULTS[i.title()]['0silly_mean.1rmse'] = base[i]\n",
    "    RESULTS[i.title()]['0silly_mean.2timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewcount Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:47:27.710090\n",
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m viewcount\u001b[0m model is 3.02\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['viewcount']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression on just viewcount\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100, # this doesn't change anything\n",
    "                      #regParam=0.3, # using regularisation parameter here useless since there is one feature\n",
    "                      #elasticNetParam=0.8,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='viewcount_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "#.addGrid(lr.regParam, [1e-3, 1.])\n",
    "#.addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='viewcount_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    \n",
    "    ## fitting on train and predicting on train/test\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "        \n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m viewcount\\033[0m model is {rmse}\")\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['1viewcount.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['1viewcount.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['1viewcount.2imprv'] = impr\n",
    "    RESULTS[i.title()]['1viewcount.3timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interesting that there are different improvements of viewcount over mean-only prediciton\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['body_word_cnt', 'titl_word_cnt', 'body_char_cnt', \n",
    "                   'titl_char_cnt', 'body_sent_cnt', 'titl_sent_cnt']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## NUMERICAL columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## create PROCESSING pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='counts_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-3, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-3, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='counts_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m counts\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2counts.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2counts.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2counts.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2counts.3timet'] = timet\n",
    "    RESULTS[i.title()]['2counts.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2counts.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "# ENGLISH\n",
    "# 8min 56s for no CV and no GRIDSEARCH\n",
    "# 17min 10s for 3-CV and no GRIDSEARCH\n",
    "# SMALL DATASETS\n",
    "# 36min 55s for no CV and no GRIDSEARCH\n",
    "# 12min 35s for 3-CV and no GRIDSEARCH\n",
    "# 8min 32s for 2-CV and no GRIDSEARCH\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "textt_variables = ['title', 'clean_body']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## textual columns\n",
    "# tokenising text cols with custom transformer\n",
    "nltk_tokeniser_body = nltkWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokeniser_title = nltkWordPunctTokeniser(\n",
    "    inputCol='title', outputCol='titl_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "# count occurence of tokens, i.e. create dfm\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol='body_words', outputCol='body_raw_feats') #!!! minDF???\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol='titl_words', outputCol='titl_raw_feats')\n",
    "\n",
    "# create IDF dfm\n",
    "idf_body = IDF(inputCol=\"body_raw_feats\", outputCol=\"body_feats\")\n",
    "idf_title = IDF(inputCol=\"titl_raw_feats\", outputCol=\"titl_feats\")\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['body_feats', 'titl_feats'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    nltk_tokeniser_body, \n",
    "    nltk_tokeniser_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title,\n",
    "    idf_body,\n",
    "    idf_title,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='tokens_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-3, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-3, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='tokens_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m tokens\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2tokens.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2tokens.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2tokens.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2tokens.3timet'] = timet\n",
    "    RESULTS[i.title()]['2tokens.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2tokens.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check predictions aren't constant\n",
    "models['health'].transform(test['health']).select('tokens_pred').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"why the heck does everything besides interpersonal have constant predictions - it's not the parameters or the size of the data\"\"\"\n",
    "\"\"\"it's the number of questions in the data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Features Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['btd[0]', 'btd[1]', 'btd[2]', 'btd[3]', 'btd[4]', 'btd[5]', 'btd[6]', 'btd[7]', 'btd[8]', \n",
    "                   'btd[9]', 'ttd[0]', 'ttd[1]', 'ttd[2]', 'ttd[3]', 'ttd[4]', 'ttd[5]', 'ttd[6]', 'ttd[7]', \n",
    "                   'ttd[8]', 'ttd[9]']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='topics_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-3, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-3, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='topics_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m topics\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2topics.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2topics.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2topics.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2topics.3timet'] = timet\n",
    "    RESULTS[i.title()]['2topics.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2topics.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:53:37.647900\n",
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m final\u001b[0m model is 3.52\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m final\u001b[0m model is 3.6\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m final\u001b[0m model is 5.17\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m final\u001b[0m model is 3.68\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m final\u001b[0m model is 28.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3final.0tr_rmse</th>\n",
       "      <th>3final.1rmse</th>\n",
       "      <th>3final.2imprv</th>\n",
       "      <th>3final.3timet</th>\n",
       "      <th>3final.4elastic</th>\n",
       "      <th>3final.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.08</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.24</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>5.29</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.30</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6.97</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>20.12</td>\n",
       "      <td>28.13</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               3final.0tr_rmse  3final.1rmse  3final.2imprv  3final.3timet  \\\n",
       "Buddhism                  3.62          3.52           0.56          10.08   \n",
       "Economics                 3.24          3.60           0.83           7.91   \n",
       "Fitness                   5.29          5.17           0.39           8.84   \n",
       "Health                    4.30          3.68           0.81           6.97   \n",
       "Interpersonal            20.12         28.13           0.35           7.03   \n",
       "\n",
       "               3final.4elastic  3final.5regular  \n",
       "Buddhism                 0.001            1.000  \n",
       "Economics                0.001            1.000  \n",
       "Fitness                  1.000            0.001  \n",
       "Health                   0.001            1.000  \n",
       "Interpersonal            1.000            1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  3final.0tr\\_rmse &  3final.1rmse &  3final.2imprv &  3final.3timet &  3final.4elastic &  3final.5regular \\\\\n",
      "\\midrule\n",
      "Buddhism      &             3.62 &          3.52 &           0.56 &          10.08 &            0.001 &            1.000 \\\\\n",
      "Economics     &             3.24 &          3.60 &           0.83 &           7.91 &            0.001 &            1.000 \\\\\n",
      "Fitness       &             5.29 &          5.17 &           0.39 &           8.84 &            1.000 &            0.001 \\\\\n",
      "Health        &             4.30 &          3.68 &           0.81 &           6.97 &            0.001 &            1.000 \\\\\n",
      "Interpersonal &            20.12 &         28.13 &           0.35 &           7.03 &            1.000 &            1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 4.32 s, sys: 1.34 s, total: 5.66 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['btd[0]', 'btd[1]', 'btd[2]', 'btd[3]', 'btd[4]', 'btd[5]', 'btd[6]', 'btd[7]', 'btd[8]', \n",
    "                   'btd[9]', 'ttd[0]', 'ttd[1]', 'ttd[2]', 'ttd[3]', 'ttd[4]', 'ttd[5]', 'ttd[6]', 'ttd[7]', \n",
    "                   'ttd[8]', 'ttd[9]', 'body_word_cnt', 'titl_word_cnt', 'body_char_cnt', \n",
    "                   'titl_char_cnt', 'body_sent_cnt', 'titl_sent_cnt']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "### DATE columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "### NUMERICAL columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "\n",
    "## create PROCESSING pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    numic_pipeline,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='finalm_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-3, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-3, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='finalm_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m final\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['3final.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['3final.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['3final.2imprv'] = impr\n",
    "    RESULTS[i.title()]['3final.3timet'] = timet\n",
    "    RESULTS[i.title()]['3final.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['3final.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(finalm_pred=2.9190986652103756),\n",
       " Row(finalm_pred=2.4109049599660364),\n",
       " Row(finalm_pred=3.158419654331349),\n",
       " Row(finalm_pred=2.9567919243386123),\n",
       " Row(finalm_pred=3.022591392683038),\n",
       " Row(finalm_pred=3.6032996635176935),\n",
       " Row(finalm_pred=3.2730229802480872),\n",
       " Row(finalm_pred=4.19333008489856),\n",
       " Row(finalm_pred=3.593894033650666),\n",
       " Row(finalm_pred=2.9712486943446104),\n",
       " Row(finalm_pred=3.007316082996332),\n",
       " Row(finalm_pred=2.83153581489662),\n",
       " Row(finalm_pred=2.6636758750639578),\n",
       " Row(finalm_pred=3.0695896812849663),\n",
       " Row(finalm_pred=3.456308669254049),\n",
       " Row(finalm_pred=3.8776198420716765),\n",
       " Row(finalm_pred=3.7269295145918573),\n",
       " Row(finalm_pred=3.6364471263597076),\n",
       " Row(finalm_pred=3.094029818129936),\n",
       " Row(finalm_pred=3.6653403486524465),\n",
       " Row(finalm_pred=3.7780235040431887),\n",
       " Row(finalm_pred=3.8600674178571555),\n",
       " Row(finalm_pred=3.3346961603972622),\n",
       " Row(finalm_pred=3.441695020198778),\n",
       " Row(finalm_pred=3.5848764123695145),\n",
       " Row(finalm_pred=3.494866165355581),\n",
       " Row(finalm_pred=3.1099708012701583),\n",
       " Row(finalm_pred=2.7625462044446207),\n",
       " Row(finalm_pred=3.4122613148927265),\n",
       " Row(finalm_pred=3.6874852742986777),\n",
       " Row(finalm_pred=3.4297691226818463),\n",
       " Row(finalm_pred=3.0632663257054955),\n",
       " Row(finalm_pred=3.505219889775492),\n",
       " Row(finalm_pred=3.5156489018802324),\n",
       " Row(finalm_pred=3.3348169479623873),\n",
       " Row(finalm_pred=3.9205654566008996),\n",
       " Row(finalm_pred=3.508316598177779),\n",
       " Row(finalm_pred=3.100972225014027),\n",
       " Row(finalm_pred=4.575630601111428),\n",
       " Row(finalm_pred=2.9979348662064185),\n",
       " Row(finalm_pred=3.8849849415193476),\n",
       " Row(finalm_pred=3.555010381034061),\n",
       " Row(finalm_pred=2.5202275987408873),\n",
       " Row(finalm_pred=3.821134330819393),\n",
       " Row(finalm_pred=3.6219892710599826),\n",
       " Row(finalm_pred=3.8336230978708272),\n",
       " Row(finalm_pred=4.2035743445088904),\n",
       " Row(finalm_pred=3.965540533620764),\n",
       " Row(finalm_pred=3.797460747907053),\n",
       " Row(finalm_pred=2.330691266329735),\n",
       " Row(finalm_pred=1.6122858069857475),\n",
       " Row(finalm_pred=3.5283553853444354),\n",
       " Row(finalm_pred=3.5347992328965194),\n",
       " Row(finalm_pred=2.680466291005122),\n",
       " Row(finalm_pred=3.5612466740024296),\n",
       " Row(finalm_pred=3.3863542567378113),\n",
       " Row(finalm_pred=3.674521031677024),\n",
       " Row(finalm_pred=3.255232653489096),\n",
       " Row(finalm_pred=3.2094148827999223),\n",
       " Row(finalm_pred=3.5433457012839376),\n",
       " Row(finalm_pred=3.511281681889474),\n",
       " Row(finalm_pred=3.225933787468679),\n",
       " Row(finalm_pred=3.0330001391397423),\n",
       " Row(finalm_pred=3.149720277360089),\n",
       " Row(finalm_pred=2.6304797387474137),\n",
       " Row(finalm_pred=3.48456264444063),\n",
       " Row(finalm_pred=3.294410134741578),\n",
       " Row(finalm_pred=2.6377949739408386),\n",
       " Row(finalm_pred=3.117162600835569),\n",
       " Row(finalm_pred=3.298936348983238),\n",
       " Row(finalm_pred=2.8130714950491043),\n",
       " Row(finalm_pred=2.9311840011752635),\n",
       " Row(finalm_pred=3.0640659742845244),\n",
       " Row(finalm_pred=2.9716770366157697),\n",
       " Row(finalm_pred=3.3207876251586277),\n",
       " Row(finalm_pred=2.227282115956215),\n",
       " Row(finalm_pred=3.698257993829862),\n",
       " Row(finalm_pred=2.976228545160242),\n",
       " Row(finalm_pred=3.337877357918193),\n",
       " Row(finalm_pred=3.6729352486242988),\n",
       " Row(finalm_pred=2.0474837446660263),\n",
       " Row(finalm_pred=3.264130949214336),\n",
       " Row(finalm_pred=3.444967632662207),\n",
       " Row(finalm_pred=3.660906949123434),\n",
       " Row(finalm_pred=3.4678706241608257),\n",
       " Row(finalm_pred=3.200272257792554),\n",
       " Row(finalm_pred=2.850881400487814),\n",
       " Row(finalm_pred=2.505267675034273),\n",
       " Row(finalm_pred=3.517372582065627),\n",
       " Row(finalm_pred=2.1682497072594877),\n",
       " Row(finalm_pred=4.021975961129315),\n",
       " Row(finalm_pred=3.5743403053809137),\n",
       " Row(finalm_pred=3.4409858347604434),\n",
       " Row(finalm_pred=2.5530824110868267),\n",
       " Row(finalm_pred=2.6324198702763146),\n",
       " Row(finalm_pred=3.4396333540266495),\n",
       " Row(finalm_pred=2.3291379207001706),\n",
       " Row(finalm_pred=4.220827123396096),\n",
       " Row(finalm_pred=2.7902371563708686),\n",
       " Row(finalm_pred=3.151935877254168)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check predictions aren't constant\n",
    "models['health'].transform(test['health']).select('finalm_pred').take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trained_pipeline\n",
    " .transform(datasets['english'])\n",
    " .select(\n",
    "    indep_text_variables + [\"prediction\"]\n",
    " )\n",
    " .write\n",
    " .parquet(\"linreg_prediction.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions = spark.read.parquet(\"linreg_prediction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.select(\"prediction\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(estimator_pipeline, 'pipeline.joblib') \n",
    "\n",
    "reloaded = load(\"pipeline.joblib\")\n",
    "\n",
    "#Now we can predict directly!\n",
    "\n",
    "reloaded.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## save models DOESN'T WORK BECAUSE: 'NLTKWordPunctTokenizer' object has no attribute '_to_java'\n",
    "for i in data_array:\n",
    "    param_dict[i].save(f'{i}-pipeline') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 0-master-notebook-pipelines.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
