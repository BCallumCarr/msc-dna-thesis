{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "\n",
    "* Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Welcome to my PySpark analysis of some StackExchange Data\"\\n'\n"
     ]
    }
   ],
   "source": [
    "## testing printing output from console\n",
    "import subprocess\n",
    "cmd = [ 'echo', '\"Welcome to my PySpark analysis of some StackExchange Data\"' ]\n",
    "output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc #garbage collection\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spark UI, version 2.4.3, is available at: http://192.168.0.26:4040/ and the defaultParallelism is 4\n"
     ]
    }
   ],
   "source": [
    "%run -i '1-load-pyspark.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load easyFunctions and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## easy functions\n",
    "%run -i 'load_parquet_data.py'\n",
    "%run -i 'show_save_results.py'\n",
    "%run -i 'show_spark_df.py'\n",
    "\n",
    "## pipeline transformers\n",
    "%run -i 'nltkWordPunctTokeniser.py'\n",
    "%run -i 'nltkSenteniser.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Initial or Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:23:49.786908\n",
      "CPU times: user 5.26 ms, sys: 2.84 ms, total: 8.1 ms\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "data_array, datasets = load_parquet_data(kind='initial', size='small', printSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buddhism: 5588\n",
      "economics: 7380\n",
      "fitness: 8100\n",
      "health: 5442\n",
      "interpersonal: 2962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29472"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in data_array:\n",
    "    s = s + datasets[i].count()\n",
    "    print(f'{i}: {datasets[i].count()}')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:23:56.071338\n",
      "\n",
      "\u001b[1m checking columns are the right types and names \u001b[0m\n",
      "\n",
      "----- buddhism -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- economics -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- fitness -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- health -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- interpersonal -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 54.3 ms, sys: 12.6 ms, total: 66.9 ms\n",
      "Wall time: 654 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '2-clean-datasets.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:23:59.367758\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '3-feat-engineering.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:59:50.511577\n",
      "CPU times: user 227 µs, sys: 183 µs, total: 410 µs\n",
      "Wall time: 280 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '5-final-eda.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:59:58.482341\n",
      "CPU times: user 216 µs, sys: 55 µs, total: 271 µs\n",
      "Wall time: 232 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '4-export-data.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'buddhism'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/1-load-pyspark.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' & '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"viewcount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' \\\\\\\\'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'buddhism'"
     ]
    }
   ],
   "source": [
    "for i in data_array:\n",
    "    s = i.title() + ' & ' + str(round( datasets[i].stat.corr(\"score\", \"viewcount\"), 2 )) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 35 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:49:36.161006\n",
      "Buddhism & 3.6 & 3.63 \\\\\n",
      "Economics & 3.62 & 3.07 \\\\\n",
      "Fitness & 5.38 & 5.12 \\\\\n",
      "Health & 4.11 & 4.07 \\\\\n",
      "Interpersonal & 24.95 & 22.78 \\\\\n",
      "CPU times: user 102 ms, sys: 31.1 ms, total: 133 ms\n",
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '6a-time-train-test-split-80.py'    \n",
    "#%run -i '6b-rand-train-test-split-80.py'\n",
    "#%run -i '6c-time-train-test-split-60.py'\n",
    "%run -i '6d-rand-train-test-split-60.py'\n",
    "\n",
    "## check standard deviations of variables\n",
    "for i in data_array:\n",
    "    s = i.title() + ' & ' + str(round( pd.to_numeric(train[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )) + ' & ' + \\\n",
    "    str(round( pd.to_numeric(test[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 275 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninteresting to see how skewed rus_stackoverflow posts are to more posts in recent years\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "interesting to see how skewed rus_stackoverflow posts are to more posts in recent years\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_save_results(results, filename='final-results.csv'):\n",
    "    '''\n",
    "    function to print and export modelling results\n",
    "    '''\n",
    "    display(pd.DataFrame.from_dict(results).T)\n",
    "    print(pd.DataFrame.from_dict(results).T.to_latex())\n",
    "    pd.DataFrame.from_dict(results).T.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silly Mean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m mean\u001b[0m model is 3.63\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m mean\u001b[0m model is 3.07\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m mean\u001b[0m model is 5.12\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m mean\u001b[0m model is 4.08\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m mean\u001b[0m model is 22.77\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array, lit, struct\n",
    "\n",
    "## choose target variable\n",
    "target = 'score'\n",
    "\n",
    "## create mean dictionaries\n",
    "y_ravi_tr_means = {}\n",
    "\n",
    "## calculate the mean of each forum, using ONLY training set\n",
    "for i in data_array:\n",
    "    y_ravi_tr_means[i] = train[i].select(target).rdd.flatMap(lambda x: x).mean()\n",
    "\n",
    "## import rmse evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "## create dictionaries for training and testing (baseline) rmse \n",
    "base = {}\n",
    "tr_rmse = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "\n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## train silly mean model by assigning training set mean for training and testing predictions\n",
    "    train[i] = train[i].withColumn('mean_pred', lit(y_ravi_tr_means[i]))\n",
    "    test[i] = test[i].withColumn('mean_pred', lit(y_ravi_tr_means[i]))\n",
    "\n",
    "    ## evaluate silly mean model, on both training and testing set\n",
    "    evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='mean_pred')\n",
    "    tr_rmse[i] = round( evaluator.evaluate(train[i]), 2)\n",
    "    base[i] = round( evaluator.evaluate(test[i]), 2)\n",
    "\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m mean\\033[0m model is {base[i]}\")\n",
    "\n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "    \n",
    "    ## store as dictionary inside RESULTS dictionary, initiating dataset name entries first\n",
    "    RESULTS[i.title()]['0silly_mean.0tr_rmse'] = tr_rmse[i]\n",
    "    RESULTS[i.title()]['0silly_mean.1rmse'] = base[i]\n",
    "    RESULTS[i.title()]['0silly_mean.2timet'] = timet\n",
    "    \n",
    "## record results\n",
    "#show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewcount Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#3min 56s\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['viewcount']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = Q(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression on just viewcount\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100, # this doesn't change anything\n",
    "                      #regParam=0.3, # using regularisation parameter here useless since there is one feature\n",
    "                      #elasticNetParam=0.8,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='viewcount_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "#.addGrid(lr.regParam, [1e-3, 1.])\n",
    "#.addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='viewcount_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    \n",
    "    ## fitting on train and predicting on train/test\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "        \n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m viewcount\\033[0m model is {rmse}\")\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['1viewcount.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['1viewcount.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['1viewcount.2imprv'] = impr\n",
    "    RESULTS[i.title()]['1viewcount.3timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interesting that there are different improvements of viewcount over mean-only prediciton\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "# ENGLISH\n",
    "# 8min 56s for no CV and no GRIDSEARCH\n",
    "# 17min 10s for 3-CV and no GRIDSEARCH\n",
    "# SMALL DATASETS\n",
    "# 36min 55s for no CV and no GRIDSEARCH\n",
    "# 12min 35s for 3-CV and no GRIDSEARCH\n",
    "# 8min 32s for 2-CV and no GRIDSEARCH\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['body_word_cnt', 'titl_word_cnt', 'body_char_cnt', \n",
    "                   'titl_char_cnt', 'body_sent_cnt', 'titl_sent_cnt']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='counts_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-3, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-3, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='counts_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m counts\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2counts.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2counts.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2counts.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2counts.3timet'] = timet\n",
    "    RESULTS[i.title()]['2counts.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2counts.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:50:02.961988\n",
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m tokens\u001b[0m model is 3.63\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m tokens\u001b[0m model is 3.07\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m tokens\u001b[0m model is 5.12\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m tokens\u001b[0m model is 4.08\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m tokens\u001b[0m model is 23.15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2tokens.0tr_rmse</th>\n",
       "      <th>2tokens.1rmse</th>\n",
       "      <th>2tokens.2imprv</th>\n",
       "      <th>2tokens.3timet</th>\n",
       "      <th>2tokens.4elastic</th>\n",
       "      <th>2tokens.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>118.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>158.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>5.38</td>\n",
       "      <td>5.12</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>169.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>87.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>18.30</td>\n",
       "      <td>23.15</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>128.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2tokens.0tr_rmse  2tokens.1rmse  2tokens.2imprv  \\\n",
       "Buddhism                   3.60           3.63           -0.00   \n",
       "Economics                  3.61           3.07           -0.00   \n",
       "Fitness                    5.38           5.12           -0.00   \n",
       "Health                     4.11           4.08           -0.00   \n",
       "Interpersonal             18.30          23.15           -1.67   \n",
       "\n",
       "               2tokens.3timet  2tokens.4elastic  2tokens.5regular  \n",
       "Buddhism               118.92               1.0               1.0  \n",
       "Economics              158.11               1.0               1.0  \n",
       "Fitness                169.01               1.0               1.0  \n",
       "Health                  87.71               1.0               1.0  \n",
       "Interpersonal          128.64               1.0               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  2tokens.0tr\\_rmse &  2tokens.1rmse &  2tokens.2imprv &  2tokens.3timet &  2tokens.4elastic &  2tokens.5regular \\\\\n",
      "\\midrule\n",
      "Buddhism      &              3.60 &           3.63 &           -0.00 &          118.92 &               1.0 &               1.0 \\\\\n",
      "Economics     &              3.61 &           3.07 &           -0.00 &          158.11 &               1.0 &               1.0 \\\\\n",
      "Fitness       &              5.38 &           5.12 &           -0.00 &          169.01 &               1.0 &               1.0 \\\\\n",
      "Health        &              4.11 &           4.08 &           -0.00 &           87.71 &               1.0 &               1.0 \\\\\n",
      "Interpersonal &             18.30 &          23.15 &           -1.67 &          128.64 &               1.0 &               1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 3.17 s, sys: 849 ms, total: 4.02 s\n",
      "Wall time: 11min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "# ENGLISH\n",
    "# 8min 56s for no CV and no GRIDSEARCH\n",
    "# 17min 10s for 3-CV and no GRIDSEARCH\n",
    "# SMALL DATASETS\n",
    "# 36min 55s for no CV and no GRIDSEARCH\n",
    "# 12min 35s for 3-CV and no GRIDSEARCH\n",
    "# 8min 32s for 2-CV and no GRIDSEARCH\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "textt_variables = ['title', 'clean_body']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "## textual columns\n",
    "# tokenising text cols with custom transformer\n",
    "nltk_tokeniser_body = NLTKWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokeniser_title = NLTKWordPunctTokeniser(\n",
    "    inputCol='title', outputCol='titl_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "# count occurence of tokens, i.e. create dfm\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol='body_words', outputCol='body_raw_feats', minDF=2)\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol='titl_words', outputCol='titl_raw_feats', minDF=2)\n",
    "\n",
    "# create IDF dfm\n",
    "idf_body = IDF(inputCol=\"body_raw_feats\", outputCol=\"body_feats\")\n",
    "idf_title = IDF(inputCol=\"titl_raw_feats\", outputCol=\"titl_feats\")\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['body_feats', 'titl_feats'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    nltk_tokeniser_body, \n",
    "    nltk_tokeniser_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title,\n",
    "    idf_body,\n",
    "    idf_title,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='tokens_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "#    .addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "#    .addGrid(lr.regParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='tokens_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m tokens\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2tokens.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2tokens.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2tokens.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2tokens.3timet'] = timet\n",
    "    RESULTS[i.title()]['2tokens.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2tokens.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check predictions aren't constant\n",
    "models['health'].transform(test['health']).select('tokens_pred').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"why the heck does everything besides interpersonal have constant predictions - it's not the parameters or the size of the data\"\"\"\n",
    "\"\"\"it's the size of the datasets\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## have a look at CV models params\n",
    "list(zip(models['health'].avgMetrics, paramGrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract best parameters\n",
    "for i in data_array:\n",
    "    # elasticnet\n",
    "    ela_key = list(models[i].bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = models[i].bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(models[i].bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = models[i].bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "    print(i)\n",
    "    print(f'elastic net: {ela_param}, reg: {reg_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:50:02.961988\n",
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m tokens\u001b[0m model is 3.63\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m tokens\u001b[0m model is 3.07\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m tokens\u001b[0m model is 5.12\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m tokens\u001b[0m model is 4.08\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m tokens\u001b[0m model is 23.15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2tokens.0tr_rmse</th>\n",
       "      <th>2tokens.1rmse</th>\n",
       "      <th>2tokens.2imprv</th>\n",
       "      <th>2tokens.3timet</th>\n",
       "      <th>2tokens.4elastic</th>\n",
       "      <th>2tokens.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>118.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>158.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>5.38</td>\n",
       "      <td>5.12</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>169.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>87.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>18.30</td>\n",
       "      <td>23.15</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>128.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2tokens.0tr_rmse  2tokens.1rmse  2tokens.2imprv  \\\n",
       "Buddhism                   3.60           3.63           -0.00   \n",
       "Economics                  3.61           3.07           -0.00   \n",
       "Fitness                    5.38           5.12           -0.00   \n",
       "Health                     4.11           4.08           -0.00   \n",
       "Interpersonal             18.30          23.15           -1.67   \n",
       "\n",
       "               2tokens.3timet  2tokens.4elastic  2tokens.5regular  \n",
       "Buddhism               118.92               1.0               1.0  \n",
       "Economics              158.11               1.0               1.0  \n",
       "Fitness                169.01               1.0               1.0  \n",
       "Health                  87.71               1.0               1.0  \n",
       "Interpersonal          128.64               1.0               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  2tokens.0tr\\_rmse &  2tokens.1rmse &  2tokens.2imprv &  2tokens.3timet &  2tokens.4elastic &  2tokens.5regular \\\\\n",
      "\\midrule\n",
      "Buddhism      &              3.60 &           3.63 &           -0.00 &          118.92 &               1.0 &               1.0 \\\\\n",
      "Economics     &              3.61 &           3.07 &           -0.00 &          158.11 &               1.0 &               1.0 \\\\\n",
      "Fitness       &              5.38 &           5.12 &           -0.00 &          169.01 &               1.0 &               1.0 \\\\\n",
      "Health        &              4.11 &           4.08 &           -0.00 &           87.71 &               1.0 &               1.0 \\\\\n",
      "Interpersonal &             18.30 &          23.15 &           -1.67 &          128.64 &               1.0 &               1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 3.17 s, sys: 849 ms, total: 4.02 s\n",
      "Wall time: 11min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "# ENGLISH\n",
    "# 8min 56s for no CV and no GRIDSEARCH\n",
    "# 17min 10s for 3-CV and no GRIDSEARCH\n",
    "# SMALL DATASETS\n",
    "# 36min 55s for no CV and no GRIDSEARCH\n",
    "# 12min 35s for 3-CV and no GRIDSEARCH\n",
    "# 8min 32s for 2-CV and no GRIDSEARCH\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "textt_variables = ['title', 'clean_body']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "## textual columns\n",
    "# tokenising text cols with custom transformer\n",
    "nltk_tokeniser_body = NLTKWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokeniser_title = NLTKWordPunctTokeniser(\n",
    "    inputCol='title', outputCol='titl_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "# count occurence of tokens, i.e. create dfm\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol='body_words', outputCol='body_raw_feats', minDF=2)\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol='titl_words', outputCol='titl_raw_feats', minDF=2)\n",
    "\n",
    "# create IDF dfm\n",
    "idf_body = IDF(inputCol=\"body_raw_feats\", outputCol=\"body_feats\")\n",
    "idf_title = IDF(inputCol=\"titl_raw_feats\", outputCol=\"titl_feats\")\n",
    "\n",
    "# get topic distributions from LDA model\n",
    "from pyspark.ml.clustering import LDA\n",
    "lda_body = LDA(k=10, maxIter=5, inputCol='body_feats', outputCol='final_body')\n",
    "lda_title = LDA(k=10, maxIter=5, inputCol='titl_feats', outputCol='final_titl')\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['final_body', 'final_titl'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "\n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    nltk_tokeniser_body, \n",
    "    nltk_tokeniser_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title,\n",
    "    idf_body,\n",
    "    idf_title,\n",
    "    lda_body,\n",
    "    lda_title,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='tokens_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "#    .addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "#    .addGrid(lr.regParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='tokens_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m tokens\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2tokens.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2tokens.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2tokens.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2tokens.3timet'] = timet\n",
    "    RESULTS[i.title()]['2tokens.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2tokens.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'inputCol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/1-load-pyspark.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'body_feats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'final_body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'inputCol'"
     ]
    }
   ],
   "source": [
    "lda_body = LDA(k=10, maxIter=5, inputCol='body_feats', outputCol='final_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokeniser_body = NLTKWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol='body_words', outputCol='features', minDF=2)\n",
    "\n",
    "mat1 = nltk_tokeniser_body.transform(datasets['interpersonal'])\n",
    "\n",
    "# TF\n",
    "mat2 = cnt_vectrizr_body.fit(mat1).transform(mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 ms, sys: 8.67 ms, total: 31.4 ms\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=10, maxIter=5)\n",
    "\n",
    "temp = lda.fit(mat2).transform(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>score</th>\n",
       "      <th>clean_date</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>body_word_cnt</th>\n",
       "      <th>titl_word_cnt</th>\n",
       "      <th>body_sent_cnt</th>\n",
       "      <th>titl_sent_cnt</th>\n",
       "      <th>body_char_cnt</th>\n",
       "      <th>titl_char_cnt</th>\n",
       "      <th>body_words</th>\n",
       "      <th>features</th>\n",
       "      <th>topicDistribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to deal with avoiding someone I don't like</td>\n",
       "      <td>6922</td>\n",
       "      <td>38</td>\n",
       "      <td>2017-06-27 17:23:39.670</td>\n",
       "      <td>Currently, as part of my work, I come into pr...</td>\n",
       "      <td>208</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1736</td>\n",
       "      <td>46</td>\n",
       "      <td>[current, ,, part, work, ,, i, come, proxim, l...</td>\n",
       "      <td>(18.0, 4.0, 23.0, 9.0, 6.0, 1.0, 3.0, 2.0, 1.0...</td>\n",
       "      <td>[0.00044454322049143266, 0.0004370769271664956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to handle accidentally bumping into a drun...</td>\n",
       "      <td>1792</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-06-27 17:25:17.937</td>\n",
       "      <td>Yesterday when I left my office, I bumped int...</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>421</td>\n",
       "      <td>69</td>\n",
       "      <td>[yesterday, i, left, offic, ,, i, bump, drunk,...</td>\n",
       "      <td>(9.0, 4.0, 7.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0016031470816361172, 0.001576217661595304, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I get someone to say their first name ...</td>\n",
       "      <td>8415</td>\n",
       "      <td>105</td>\n",
       "      <td>2017-06-27 17:29:06.940</td>\n",
       "      <td>I often face the problem of forgetting the na...</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>85</td>\n",
       "      <td>[i, often, face, problem, forget, name, person...</td>\n",
       "      <td>(4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.002820006528161007, 0.002772676504581645, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joining an existing group of friends</td>\n",
       "      <td>1941</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-06-27 17:30:02.927</td>\n",
       "      <td>Many times we try to blend in with some frien...</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>36</td>\n",
       "      <td>[mani, time, tri, blend, friend, ', friend, .,...</td>\n",
       "      <td>(6.0, 8.0, 9.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, ...</td>\n",
       "      <td>[0.0008526431202516887, 0.0008383184900333576,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to react to an excuse if it wasn't \"Ok\"?</td>\n",
       "      <td>1545</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-27 17:33:09.793</td>\n",
       "      <td>I was walking down the street, when a rushing...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>411</td>\n",
       "      <td>44</td>\n",
       "      <td>[i, walk, street, ,, rush, older, man, barg, ....</td>\n",
       "      <td>(4.0, 2.0, 5.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.001823467879329865, 0.001792854197665454, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  viewcount  score  \\\n",
       "0     How to deal with avoiding someone I don't like       6922     38   \n",
       "1  How to handle accidentally bumping into a drun...       1792     15   \n",
       "2  How can I get someone to say their first name ...       8415    105   \n",
       "3               Joining an existing group of friends       1941     20   \n",
       "4       How to react to an excuse if it wasn't \"Ok\"?       1545      0   \n",
       "\n",
       "               clean_date                                         clean_body  \\\n",
       "0 2017-06-27 17:23:39.670   Currently, as part of my work, I come into pr...   \n",
       "1 2017-06-27 17:25:17.937   Yesterday when I left my office, I bumped int...   \n",
       "2 2017-06-27 17:29:06.940   I often face the problem of forgetting the na...   \n",
       "3 2017-06-27 17:30:02.927   Many times we try to blend in with some frien...   \n",
       "4 2017-06-27 17:33:09.793   I was walking down the street, when a rushing...   \n",
       "\n",
       "   body_word_cnt  titl_word_cnt  body_sent_cnt  titl_sent_cnt  body_char_cnt  \\\n",
       "0            208              7             11              1           1736   \n",
       "1             57              8              5              1            421   \n",
       "2             32             13              3              1            256   \n",
       "3            108              4             10              1            966   \n",
       "4             50              7              4              1            411   \n",
       "\n",
       "   titl_char_cnt                                         body_words  \\\n",
       "0             46  [current, ,, part, work, ,, i, come, proxim, l...   \n",
       "1             69  [yesterday, i, left, offic, ,, i, bump, drunk,...   \n",
       "2             85  [i, often, face, problem, forget, name, person...   \n",
       "3             36  [mani, time, tri, blend, friend, ', friend, .,...   \n",
       "4             44  [i, walk, street, ,, rush, older, man, barg, ....   \n",
       "\n",
       "                                            features  \\\n",
       "0  (18.0, 4.0, 23.0, 9.0, 6.0, 1.0, 3.0, 2.0, 1.0...   \n",
       "1  (9.0, 4.0, 7.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2  (4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "3  (6.0, 8.0, 9.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, ...   \n",
       "4  (4.0, 2.0, 5.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                   topicDistribution  \n",
       "0  [0.00044454322049143266, 0.0004370769271664956...  \n",
       "1  [0.0016031470816361172, 0.001576217661595304, ...  \n",
       "2  [0.002820006528161007, 0.002772676504581645, 0...  \n",
       "3  [0.0008526431202516887, 0.0008383184900333576,...  \n",
       "4  [0.001823467879329865, 0.001792854197665454, 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_spark_df(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributedLDAModel_91f80a60c3e9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = VectorAssembler(inputCols=['body_raw_feats'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/1-load-pyspark.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lda_model = lda.transform(process.transform(mat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(9624, 10, [28.1371, 14.3826, 143.8924, 21.5715, 38.1571, 36.4679, 9.8236, 45.3612, ..., 1.7004, 0.9735, 0.8829, 0.8919, 1.9658, 0.7925, 3.4809, 0.9884], 0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 9624 words):\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned topics (as distributions over vocab of \" + str(lda_model.vocabSize())\n",
    "      + \" words):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[731, 2, 236, 172, 70],\n",
       " [160, 2347, 1897, 674, 427],\n",
       " [7, 2, 9, 10, 20],\n",
       " [2, 9, 295, 82, 12],\n",
       " [247, 45, 2, 775, 1300],\n",
       " [28, 244, 242, 147, 52],\n",
       " [2, 18, 181, 8, 62],\n",
       " [323, 144, 39, 16, 5],\n",
       " [16, 18, 97, 38, 291],\n",
       " [46, 36, 371, 51, 1321]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.describeTopics(5).select(\"termIndices\").rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"features\" does not exist.\\nAvailable fields: title, viewcount, score, clean_date, clean_body, body_word_cnt, titl_word_cnt, body_sent_cnt, titl_sent_cnt, body_char_cnt, titl_char_cnt, body_words, body_raw_feats, body_feats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o12150.transform.\n: java.lang.IllegalArgumentException: Field \"features\" does not exist.\nAvailable fields: title, viewcount, score, clean_date, clean_body, body_word_cnt, titl_word_cnt, body_sent_cnt, titl_sent_cnt, body_char_cnt, titl_char_cnt, body_words, body_raw_feats, body_feats\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\n\tat org.apache.spark.ml.util.DatasetUtils$.columnToVector(DatasetUtils.scala:44)\n\tat org.apache.spark.ml.clustering.LDAModel.transform(LDA.scala:466)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/6d-rand-train-test-split-60.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"features\" does not exist.\\nAvailable fields: title, viewcount, score, clean_date, clean_body, body_word_cnt, titl_word_cnt, body_sent_cnt, titl_sent_cnt, body_char_cnt, titl_char_cnt, body_words, body_raw_feats, body_feats'"
     ]
    }
   ],
   "source": [
    "lda_model.transform(mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(9624, 10, [28.1371, 14.3826, 143.8924, 21.5715, 38.1571, 36.4679, 9.8236, 45.3612, ..., 1.7004, 0.9735, 0.8829, 0.8919, 1.9658, 0.7925, 3.4809, 0.9884], 0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LocalLDAModel' object has no attribute 'topicDistributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/6d-rand-train-test-split-60.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopicDistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LocalLDAModel' object has no attribute 'topicDistributions'"
     ]
    }
   ],
   "source": [
    "lda_model.topicDistributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_list = {}\n",
    "for i in data_array:\n",
    "    lda_model_list[i] = lda.fit(mat3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "max_iterations = 100\n",
    "lda_model = LDA.train(mat3[['index','features']].map(list), k=num_topics, maxIterations=max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
    "cvmodel = cv.fit(df_txts)\n",
    "result_cv = cvmodel.transform(df_txts)\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "\n",
    "## custom transformer to spread sparse vectors into individual columns\n",
    "class VectorMLliber(Transformer):\n",
    "    \"\"\"\n",
    "    A custom Transformer which converts a column of pyspark.ml vectors to multiple pyspark.mllib vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputCol=None):\n",
    "        super(VectorMLliber, self).__init__()\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        def f(v):\n",
    "            return Vectors.sparse(v.size, v.indices, v.values)\n",
    "        \n",
    "        df = df.rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???????????\n",
    "VectorMLliber_body = VectorMLliber(inputCol='body_features')\n",
    "VectorMLliber_title = VectorMLliber(inputCol='titl_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)\n",
    "\n",
    "features = {}\n",
    "feature_vec_list = {}\n",
    "for i in data_array:\n",
    "    features[i] = word_feat_list[i].select(\"features\")\n",
    "    feature_vec_list[i] = features[i].rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "    feature_vec_list[i].cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trained_pipeline\n",
    " .transform(datasets['english'])\n",
    " .select(\n",
    "    indep_text_variables + [\"prediction\"]\n",
    " )\n",
    " .write\n",
    " .parquet(\"linreg_prediction.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions = spark.read.parquet(\"linreg_prediction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.select(\"prediction\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(estimator_pipeline, 'pipeline.joblib') \n",
    "\n",
    "reloaded = load(\"pipeline.joblib\")\n",
    "\n",
    "#Now we can predict directly!\n",
    "\n",
    "reloaded.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## save models DOESN'T WORK BECAUSE: 'NLTKWordPunctTokenizer' object has no attribute '_to_java'\n",
    "for i in data_array:\n",
    "    param_dict[i].save(f'{i}-pipeline') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 0-master-notebook-pipelines.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
