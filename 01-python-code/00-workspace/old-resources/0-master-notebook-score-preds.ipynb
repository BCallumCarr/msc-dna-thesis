{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "\n",
    "* Decide on viewcount threshold to eliminate views?\n",
    "* Get feature columns working\n",
    "* Build an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Welcome to my PySpark analysis of some StackExchange Data\"\\n'\n"
     ]
    }
   ],
   "source": [
    "## testing printing output from console\n",
    "import subprocess\n",
    "cmd = [ 'echo', '\"Welcome to my PySpark analysis of some StackExchange Data\"' ]\n",
    "output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PySpark and Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spark UI is available at: http://192.168.0.26:4040/ and the defaultParallelism is 4\n"
     ]
    }
   ],
   "source": [
    "%run -i '1-load-pyspark.py'\n",
    "\n",
    "## array of dataset names to loop through in analysis\n",
    "data_array = [\n",
    "    \"english\",\n",
    "    \"rus_stackoverflow\",\n",
    "    \"superuser\",\n",
    "    \"stackoverflow\",\n",
    "    \"math\"\n",
    "]\n",
    "\n",
    "# overwrite to be last one\n",
    "data_array = [\n",
    "    \"buddhism\",\n",
    "    \"economics\",\n",
    "    \"fitness\",\n",
    "    \"health\",\n",
    "    \"interpersonal\"\n",
    "]\n",
    "\n",
    "datasets = {}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:06:58.419304\n",
      "CPU times: user 373 µs, sys: 121 µs, total: 494 µs\n",
      "Wall time: 428 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '2-load-datasets.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spark_df(df, n=5):\n",
    "    '''\n",
    "    function to better print spark df entries\n",
    "    '''\n",
    "    display(pd.DataFrame(df.head(n), columns=df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:06:58.443372\n",
      "CPU times: user 281 µs, sys: 80 µs, total: 361 µs\n",
      "Wall time: 301 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '3-clean-datasets.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:06:58.460841\n",
      "CPU times: user 142 µs, sys: 53 µs, total: 195 µs\n",
      "Wall time: 152 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '4a-best-worst-qs.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:06:58.470522\n",
      "Buddhism:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'buddhism'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/4b-final-eda.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i.title()}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{datasets[i].sort(col('clean_date').desc()).select('clean_date').take(1)[0][0]}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'buddhism'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 4.64 ms, total: 17.4 ms\n",
      "Wall time: 16.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '4b-final-eda.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Clean Data with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:07:10.883463\n",
      "CPU times: user 120 µs, sys: 88 µs, total: 208 µs\n",
      "Wall time: 140 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '5-export-data.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'buddhism'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/lse-msc-thesis-brad/01-python-code/00-workspace/4b-final-eda.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' & '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"viewcount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' \\\\\\\\'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'buddhism'"
     ]
    }
   ],
   "source": [
    "for i in data_array:\n",
    "    s = i.title() + ' & ' + str(round( datasets[i].stat.corr(\"score\", \"viewcount\"), 2 )) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 ms, sys: 2.36 ms, total: 5.43 ms\n",
      "Wall time: 4.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## load clean data\n",
    "for i in data_array:\n",
    "    datasets[i] = (\n",
    "        spark\n",
    "        .read\n",
    "        .load(f'clean-data/{i}.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split Temporally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buddhism: 5588\n",
      "economics: 7380\n",
      "fitness: 8100\n",
      "health: 5442\n",
      "interpersonal: 2962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29472"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in data_array:\n",
    "    s = s + datasets[i].count()\n",
    "    print(f'{i}: {datasets[i].count()}')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:17:06.385655\n",
      "Buddhism & 3.6 & 3.63 \\\\\n",
      "Economics & 3.62 & 3.07 \\\\\n",
      "Fitness & 5.38 & 5.12 \\\\\n",
      "Health & 4.11 & 4.07 \\\\\n",
      "Interpersonal & 24.95 & 22.78 \\\\\n",
      "CPU times: user 87.5 ms, sys: 48.4 ms, total: 136 ms\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '6a-time-train-test-split-80.py'    \n",
    "#%run -i '6b-rand-train-test-split-80.py'\n",
    "#%run -i '6c-time-train-test-split-60.py'\n",
    "%run -i '6d-rand-train-test-split-60.py'\n",
    "\n",
    "## check standard deviations of variables\n",
    "for i in data_array:\n",
    "    s = i.title() + ' & ' + str(round( pd.to_numeric(train[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )) + ' & ' + \\\n",
    "    str(round( pd.to_numeric(test[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninteresting to see how skewed rus_stackoverflow posts are to more posts in recent years\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "interesting to see how skewed rus_stackoverflow posts are to more posts in recent years\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_save_results(results, filename='final-results.csv'):\n",
    "    '''\n",
    "    function to print and export modelling results\n",
    "    '''\n",
    "    display(pd.DataFrame.from_dict(results).T)\n",
    "    print(pd.DataFrame.from_dict(results).T.to_latex())\n",
    "    pd.DataFrame.from_dict(results).T.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silly Mean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m mean\u001b[0m model is 3.63\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m mean\u001b[0m model is 3.07\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m mean\u001b[0m model is 5.12\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m mean\u001b[0m model is 4.08\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m mean\u001b[0m model is 22.77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0silly_mean.0tr_rmse</th>\n",
       "      <th>0silly_mean.1rmse</th>\n",
       "      <th>0silly_mean.2timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>5.38</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>24.94</td>\n",
       "      <td>22.77</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0silly_mean.0tr_rmse  0silly_mean.1rmse  0silly_mean.2timet\n",
       "Buddhism                       3.60               3.63                0.37\n",
       "Economics                      3.62               3.07                0.29\n",
       "Fitness                        5.38               5.12                0.26\n",
       "Health                         4.11               4.08                0.26\n",
       "Interpersonal                 24.94              22.77                0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  0silly\\_mean.0tr\\_rmse &  0silly\\_mean.1rmse &  0silly\\_mean.2timet \\\\\n",
      "\\midrule\n",
      "Buddhism      &                  3.60 &               3.63 &                0.37 \\\\\n",
      "Economics     &                  3.62 &               3.07 &                0.29 \\\\\n",
      "Fitness       &                  5.38 &               5.12 &                0.26 \\\\\n",
      "Health        &                  4.11 &               4.08 &                0.26 \\\\\n",
      "Interpersonal &                 24.94 &              22.77 &                0.25 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array, lit, struct\n",
    "\n",
    "## choose target variable\n",
    "target = 'score'\n",
    "\n",
    "## create mean dictionaries\n",
    "y_ravi_tr_means = {}\n",
    "\n",
    "## calculate the mean of each forum, using ONLY training set\n",
    "for i in data_array:\n",
    "    y_ravi_tr_means[i] = train[i].select(target).rdd.flatMap(lambda x: x).mean()\n",
    "\n",
    "## import rmse evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "## create dictionaries for training and testing (baseline) rmse \n",
    "base = {}\n",
    "tr_rmse = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "\n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## train silly mean model by assigning training set mean for training and testing predictions\n",
    "    train[i] = train[i].withColumn('mean_pred', lit(y_ravi_tr_means[i]))\n",
    "    test[i] = test[i].withColumn('mean_pred', lit(y_ravi_tr_means[i]))\n",
    "\n",
    "    ## evaluate silly mean model, on both training and testing set\n",
    "    evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='mean_pred')\n",
    "    tr_rmse[i] = round( evaluator.evaluate(train[i]), 2)\n",
    "    base[i] = round( evaluator.evaluate(test[i]), 2)\n",
    "\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m mean\\033[0m model is {base[i]}\")\n",
    "\n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "    \n",
    "    ## store as dictionary inside RESULTS dictionary, initiating dataset name entries first\n",
    "    RESULTS[i.title()]['0silly_mean.0tr_rmse'] = tr_rmse[i]\n",
    "    RESULTS[i.title()]['0silly_mean.1rmse'] = base[i]\n",
    "    RESULTS[i.title()]['0silly_mean.2timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewcount Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:17:45.907751\n",
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m viewcount\u001b[0m model is 3.24\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m viewcount\u001b[0m model is 2.95\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m viewcount\u001b[0m model is 4.73\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m viewcount\u001b[0m model is 4.03\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m viewcount\u001b[0m model is 10.38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1viewcount.0tr_rmse</th>\n",
       "      <th>1viewcount.1rmse</th>\n",
       "      <th>1viewcount.2imprv</th>\n",
       "      <th>1viewcount.3timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.24</td>\n",
       "      <td>3.24</td>\n",
       "      <td>10.74</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.45</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>5.07</td>\n",
       "      <td>4.73</td>\n",
       "      <td>7.62</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.08</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>12.07</td>\n",
       "      <td>10.38</td>\n",
       "      <td>54.41</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1viewcount.0tr_rmse  1viewcount.1rmse  1viewcount.2imprv  \\\n",
       "Buddhism                      3.24              3.24              10.74   \n",
       "Economics                     3.45              2.95               3.91   \n",
       "Fitness                       5.07              4.73               7.62   \n",
       "Health                        4.08              4.03               1.23   \n",
       "Interpersonal                12.07             10.38              54.41   \n",
       "\n",
       "               1viewcount.3timet  \n",
       "Buddhism                    3.51  \n",
       "Economics                   3.30  \n",
       "Fitness                     3.00  \n",
       "Health                      2.69  \n",
       "Interpersonal               2.76  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  1viewcount.0tr\\_rmse &  1viewcount.1rmse &  1viewcount.2imprv &  1viewcount.3timet \\\\\n",
      "\\midrule\n",
      "Buddhism      &                 3.24 &              3.24 &              10.74 &               3.51 \\\\\n",
      "Economics     &                 3.45 &              2.95 &               3.91 &               3.30 \\\\\n",
      "Fitness       &                 5.07 &              4.73 &               7.62 &               3.00 \\\\\n",
      "Health        &                 4.08 &              4.03 &               1.23 &               2.69 \\\\\n",
      "Interpersonal &                12.07 &             10.38 &              54.41 &               2.76 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 959 ms, sys: 277 ms, total: 1.24 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#3min 56s\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['viewcount']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression on just viewcount\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100, # this doesn't change anything\n",
    "                      #regParam=0.3, # using regularisation parameter here useless since there is one feature\n",
    "                      #elasticNetParam=0.8,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='viewcount_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "#.addGrid(lr.regParam, [1e-3, 1.])\n",
    "#.addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='viewcount_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    \n",
    "    ## fitting on train and predicting on train/test\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "        \n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m viewcount\\033[0m model is {rmse}\")\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['1viewcount.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['1viewcount.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['1viewcount.2imprv'] = impr\n",
    "    RESULTS[i.title()]['1viewcount.3timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interesting that there are different improvements of viewcount over mean-only prediciton\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 1559 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "import gc\n",
    "collected = gc.collect()\n",
    "print('Garbage collector: collected %d objects.' % collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "###### TOKENISER ######\n",
    "#######################\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "## custom transformer for nltk tokenisation\n",
    "class NLTKWordPunctTokeniser(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        super(NLTKWordPunctTokeniser, self).__init__()\n",
    "        self.stopwords = Param(self, \"stopwords\", \"\")\n",
    "        self._setDefault(stopwords=set())\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setStopwords(self, value):\n",
    "        self._paramMap[self.stopwords] = value\n",
    "        return self\n",
    "\n",
    "    def getStopwords(self):\n",
    "        return self.getOrDefault(self.stopwords)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        stopwords = self.getStopwords()\n",
    "\n",
    "        def f(s):\n",
    "            # get tokens with separate punctuation\n",
    "            tokens = nltk.tokenize.wordpunct_tokenize(s)\n",
    "            # sort out russian stopwords\n",
    "            #if ('я' in tokens):\n",
    "            #    tokens = [t for t in tokens if t not in nltk.corpus.stopwords.words('russian')]\n",
    "            # remove english stopwords\n",
    "            tokens = [t for t in tokens if t not in stopwords]\n",
    "            # remove single letters\n",
    "            #tokens = [t for t in tokens if not len(t)==1] # this removes single punctuation as well\n",
    "            # stemming the words\n",
    "            tokens = [ps.stem(t) for t in tokens]\n",
    "            # convert to lower case\n",
    "            return [t.lower() for t in tokens]\n",
    "    \n",
    "        t = ArrayType(StringType())\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:18:29.791803\n",
      "The root-mean-square error of \u001b[94mbuddhism's\u001b[0m\u001b[92m tokens\u001b[0m model is 3.63\n",
      "The root-mean-square error of \u001b[94meconomics's\u001b[0m\u001b[92m tokens\u001b[0m model is 3.07\n",
      "The root-mean-square error of \u001b[94mfitness's\u001b[0m\u001b[92m tokens\u001b[0m model is 5.12\n",
      "The root-mean-square error of \u001b[94mhealth's\u001b[0m\u001b[92m tokens\u001b[0m model is 4.08\n",
      "The root-mean-square error of \u001b[94minterpersonal's\u001b[0m\u001b[92m tokens\u001b[0m model is 23.15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2tokens.0tr_rmse</th>\n",
       "      <th>2tokens.1rmse</th>\n",
       "      <th>2tokens.2imprv</th>\n",
       "      <th>2tokens.3timet</th>\n",
       "      <th>2tokens.4elastic</th>\n",
       "      <th>2tokens.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buddhism</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>240.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>331.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitness</th>\n",
       "      <td>5.38</td>\n",
       "      <td>5.12</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>421.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>189.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpersonal</th>\n",
       "      <td>18.30</td>\n",
       "      <td>23.15</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>219.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2tokens.0tr_rmse  2tokens.1rmse  2tokens.2imprv  \\\n",
       "Buddhism                   3.60           3.63           -0.00   \n",
       "Economics                  3.61           3.07           -0.00   \n",
       "Fitness                    5.38           5.12           -0.00   \n",
       "Health                     4.11           4.08           -0.00   \n",
       "Interpersonal             18.30          23.15           -1.67   \n",
       "\n",
       "               2tokens.3timet  2tokens.4elastic  2tokens.5regular  \n",
       "Buddhism               240.07               1.0               1.0  \n",
       "Economics              331.80               1.0               1.0  \n",
       "Fitness                421.14               1.0               1.0  \n",
       "Health                 189.87               1.0               1.0  \n",
       "Interpersonal          219.58               1.0               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  2tokens.0tr\\_rmse &  2tokens.1rmse &  2tokens.2imprv &  2tokens.3timet &  2tokens.4elastic &  2tokens.5regular \\\\\n",
      "\\midrule\n",
      "Buddhism      &              3.60 &           3.63 &           -0.00 &          240.07 &               1.0 &               1.0 \\\\\n",
      "Economics     &              3.61 &           3.07 &           -0.00 &          331.80 &               1.0 &               1.0 \\\\\n",
      "Fitness       &              5.38 &           5.12 &           -0.00 &          421.14 &               1.0 &               1.0 \\\\\n",
      "Health        &              4.11 &           4.08 &           -0.00 &          189.87 &               1.0 &               1.0 \\\\\n",
      "Interpersonal &             18.30 &          23.15 &           -1.67 &          219.58 &               1.0 &               1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 8.26 s, sys: 2.25 s, total: 10.5 s\n",
      "Wall time: 23min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "# ENGLISH\n",
    "# 8min 56s for no CV and no GRIDSEARCH\n",
    "# 17min 10s for 3-CV and no GRIDSEARCH\n",
    "# SMALL DATASETS\n",
    "# 36min 55s for no CV and no GRIDSEARCH\n",
    "# 12min 35s for 3-CV and no GRIDSEARCH\n",
    "# 8min 32s for 2-CV and no GRIDSEARCH\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "textt_variables = ['title', 'clean_body']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "## textual columns\n",
    "# tokenising text cols with custom transformer\n",
    "nltk_tokeniser_body = NLTKWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokeniser_title = NLTKWordPunctTokeniser(\n",
    "    inputCol='title', outputCol='titl_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "# count occurence of tokens, i.e. create dfm\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol='body_words', outputCol='body_feats', minDF=2)\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol='titl_words', outputCol='titl_feats', minDF=2)\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['body_feats', 'titl_feats'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    nltk_tokeniser_body, \n",
    "    nltk_tokeniser_title,\n",
    "    #token_counter_body,\n",
    "    #token_counter_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='tokens_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "#    .addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "#    .addGrid(lr.regParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='tokens_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m tokens\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2tokens.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2tokens.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2tokens.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2tokens.3timet'] = timet\n",
    "    RESULTS[i.title()]['2tokens.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2tokens.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check predictions aren't constant\n",
    "models['health'].transform(test['health']).select('tokens_pred').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"why the heck does everything besides interpersonal have constant predictions - it's not the parameters or the size of the data\"\"\"\n",
    "\"\"\"it's the size of the datasets\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## have a look at CV models params\n",
    "list(zip(models['health'].avgMetrics, paramGrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract best parameters\n",
    "for i in data_array:\n",
    "    # elasticnet\n",
    "    ela_key = list(models[i].bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = models[i].bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(models[i].bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = models[i].bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "    print(i)\n",
    "    print(f'elastic net: {ela_param}, reg: {reg_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to get sentence and token count to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = spark.createDataFrame(datasets['economics'].take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spark_df(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feat_list = tester4.transform( tester3.fit(tester.transform(df_)).transform(tester.transform(df_)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_feat_list.select('features').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_spark_df(word_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feat_list.select(\"features\").rdd.map(lambda r: r[0][0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feat_list.select(\"features\").rdd.map(lambda r: r[0]).map(lambda r: (r,1)).reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = NLTKWordPunctTokeniser(\n",
    "    inputCol='title', outputCol='title_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "tester2 = NLTKWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester3 = CountVectorizer(inputCol=\"title_words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester4 = NLTKCounter(inputCol='features', outputCol='final_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "###### SENTENISER ######\n",
    "########################\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "## custom transformer for nltk tokenisation\n",
    "class NLTKSenteniser(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        super(NLTKWordPunctTokenizer, self).__init__()\n",
    "        self.stopwords = Param(self, \"stopwords\", \"\")\n",
    "        self._setDefault(stopwords=set())\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setStopwords(self, value):\n",
    "        self._paramMap[self.stopwords] = value\n",
    "        return self\n",
    "\n",
    "    def getStopwords(self):\n",
    "        return self.getOrDefault(self.stopwords)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        stopwords = self.getStopwords()\n",
    "\n",
    "        def f(s):\n",
    "            # get tokens with separate punctuation\n",
    "            tokens = nltk.tokenize.wordpunct_tokenize(s)\n",
    "            # sort out russian stopwords\n",
    "            if ('я' in tokens):\n",
    "                tokens = [t for t in tokens if t not in nltk.corpus.stopwords.words('russian')]\n",
    "            # remove english stopwords\n",
    "            tokens = [t for t in tokens if t not in stopwords]\n",
    "            # remove single letters\n",
    "            tokens = [t for t in tokens if not len(t)==1]\n",
    "            # stemming the words\n",
    "            tokens = [ps.stem(t) for t in tokens]\n",
    "            # convert to lower case\n",
    "            return [t.lower() for t in tokens]\n",
    "    \n",
    "        t = ArrayType(StringType())\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "####### COUNTER #######\n",
    "#######################\n",
    "\n",
    "import nltk\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "## custom transformer for nltk tokenisation\n",
    "class NLTKCounter(Transformer, HasInputCol, HasOutputCol):\n",
    "    '''\n",
    "    Takes in cnt_vectrizr to count number of tokens per question\n",
    "    '''\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(NLTKCounter, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "\n",
    "        def f(s):\n",
    "            return 1\n",
    "    \n",
    "        t = ArrayType(StringType())\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import elements from natural language toolkit\n",
    "import nltk\n",
    "#nltk.download('all') # uncomment after first run as admin check\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def get_tokens(line):\n",
    "    '''\n",
    "    Function to parse text features\n",
    "    '''\n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuations from each word\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # lemmatizing the words, see https://en.wikipedia.org/wiki/Lemmatisation\n",
    "    '''lemmatise or stem???'''\n",
    "    words = [lmtzr.lemmatize(w) for w in words]\n",
    "    # remove single letters\n",
    "    words = [word for word in words if not len(word)==1]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "\n",
    "## custom transformer to spread sparse vectors into individual columns\n",
    "class VectorMLliber(Transformer):\n",
    "    \"\"\"\n",
    "    A custom Transformer which converts a column of pyspark.ml vectors to multiple pyspark.mllib vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputCol=None):\n",
    "        super(VectorMLliber, self).__init__()\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        def f(v):\n",
    "            return Vectors.sparse(v.size, v.indices, v.values)\n",
    "        \n",
    "        df = df.rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???????????\n",
    "VectorMLliber_body = VectorMLliber(inputCol='body_features')\n",
    "VectorMLliber_title = VectorMLliber(inputCol='titl_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)\n",
    "\n",
    "features = {}\n",
    "feature_vec_list = {}\n",
    "for i in data_array:\n",
    "    features[i] = word_feat_list[i].select(\"features\")\n",
    "    feature_vec_list[i] = features[i].rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "    feature_vec_list[i].cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trained_pipeline\n",
    " .transform(datasets['english'])\n",
    " .select(\n",
    "    indep_text_variables + [\"prediction\"]\n",
    " )\n",
    " .write\n",
    " .parquet(\"linreg_prediction.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions = spark.read.parquet(\"linreg_prediction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.select(\"prediction\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(estimator_pipeline, 'pipeline.joblib') \n",
    "\n",
    "reloaded = load(\"pipeline.joblib\")\n",
    "\n",
    "#Now we can predict directly!\n",
    "\n",
    "reloaded.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## save models DOESN'T WORK BECAUSE: 'NLTKWordPunctTokenizer' object has no attribute '_to_java'\n",
    "for i in data_array:\n",
    "    param_dict[i].save(f'{i}-pipeline') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 0-master-notebook-pipelines.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
