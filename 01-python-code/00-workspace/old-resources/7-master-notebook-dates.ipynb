{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "\n",
    "* Decide on viewcount threshold to eliminate views?\n",
    "* Get feature columns working\n",
    "* Build an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Welcome to my PySpark analysis of some StackExchange Data\"\\n'\n"
     ]
    }
   ],
   "source": [
    "## testing printing output from console\n",
    "import subprocess\n",
    "cmd = [ 'echo', '\"Welcome to my PySpark analysis of some StackExchange Data\"' ]\n",
    "output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PySpark and Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spark UI is available at: http://192.168.0.26:4040/ and the defaultParallelism is 4\n",
      "The data_array is: ['english', 'math', 'rus_stackoverflow', 'stackoverflow', 'superuser']\n"
     ]
    }
   ],
   "source": [
    "%run -i '1-load-pyspark-and-structs.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:46:26.632131\n",
      "CPU times: user 375 µs, sys: 138 µs, total: 513 µs\n",
      "Wall time: 455 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '2-load-datasets.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spark_df(df, n=5):\n",
    "    '''\n",
    "    function to better print spark df entries\n",
    "    '''\n",
    "    display(pd.DataFrame(df.head(n), columns=df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:46:26.658031\n",
      "CPU times: user 268 µs, sys: 72 µs, total: 340 µs\n",
      "Wall time: 283 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '3-clean-datasets.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Target, EDA and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:46:26.671680\n",
      "CPU times: user 377 µs, sys: 108 µs, total: 485 µs\n",
      "Wall time: 453 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "#%run -i '4-define-target-eda-export.py'\n",
    "\n",
    "#NB TO DO: Find threshold to delete low views to make sure users that can vote have seen the question\n",
    "\n",
    "'''\n",
    "vc_thresh_data = {}\n",
    "\n",
    "## finding means of viewcounts across fora\n",
    "\n",
    "for i in data_array:\n",
    "    vc_thresh_data[i] = datasets[i].select(\"viewcount\").rdd.flatMap(lambda x: x).mean()\n",
    "\n",
    "vc_thresh_data'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 ms, sys: 2.14 ms, total: 5.37 ms\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## load clean data\n",
    "for i in data_array:\n",
    "    datasets[i] = (\n",
    "        spark\n",
    "        .read\n",
    "        .load(f'clean-data/{i}.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english: 0.20050307879670837, from 17616 and 87859\n",
      "math: 0.22927435077324415, from 198276 and 864798\n",
      "rus_stackoverflow: 0.4540735776836319, from 79956 and 176086\n",
      "stackoverflow: 0.20690967926144474, from 60872 and 294196\n",
      "superuser: 0.12467468017854172, from 44216 and 354651\n",
      "CPU times: user 23.9 ms, sys: 7.71 ms, total: 31.7 ms\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "        \n",
    "## create train and test dictionaries\n",
    "train = {}\n",
    "test = {}\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "## assign train and test sets, based on after certain date\n",
    "for i in data_array:\n",
    "    date = '2018-01-01' # date used to split data\n",
    "    train[i] = datasets[i].filter(datasets[i]['clean_date'] < lit(date))\n",
    "    test[i] = datasets[i].filter(datasets[i]['clean_date'] >= lit(date))\n",
    "    numer = test[i].count()\n",
    "    denom = train[i].count()\n",
    "    frac = numer/denom\n",
    "    print(f'{i}: {frac}, from {numer} and {denom}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninteresting to see how skewed rus_stackoverflow posts are to more posts in recent years\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "interesting to see how skewed rus_stackoverflow posts are to more posts in recent years\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    RESULTS[i] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english': {},\n",
       " 'math': {},\n",
       " 'rus_stackoverflow': {},\n",
       " 'stackoverflow': {},\n",
       " 'superuser': {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silly Mean and Median Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array, lit, struct\n",
    "\n",
    "## create mean dictionaries\n",
    "y_ravi_means = {}\n",
    "\n",
    "## calculate the mean of each forum, using ONLY train set\n",
    "for i in data_array:\n",
    "    y_ravi_means[i] = train[i].select('y_ravi').rdd.flatMap(lambda x: x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[94menglish's\u001b[0m\u001b[92m mean\u001b[0m model is 0.020986\n",
      "The root-mean-square error of \u001b[94mmath's\u001b[0m\u001b[92m mean\u001b[0m model is 0.027263\n",
      "The root-mean-square error of \u001b[94mrus_stackoverflow's\u001b[0m\u001b[92m mean\u001b[0m model is 0.023957\n",
      "The root-mean-square error of \u001b[94mstackoverflow's\u001b[0m\u001b[92m mean\u001b[0m model is 0.02202\n",
      "The root-mean-square error of \u001b[94msuperuser's\u001b[0m\u001b[92m mean\u001b[0m model is 0.02028\n"
     ]
    }
   ],
   "source": [
    "## import rmse evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "## create baselines dictionary\n",
    "base = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "\n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## train silly mean model by assigning full mean to each row of test\n",
    "    test[i] = test[i].withColumn('mean_pred', lit(y_ravi_means[i]))\n",
    "\n",
    "    ## evaluate silly mean model, ONLY on test set\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"y_ravi\", predictionCol=\"mean_pred\")\n",
    "    base[i] = round( evaluator.evaluate(test[i]), 6)\n",
    "\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m mean\\033[0m model is {base[i]}\")\n",
    "\n",
    "    ## record time taken\n",
    "    timt = round( time.time() - t0, 2 )\n",
    "    \n",
    "    ## store as dictionary inside RESULTS dictionary, initiating dataset name entries first\n",
    "    RESULTS[i]['silly_mean.rmse'] = base[i]\n",
    "    RESULTS[i]['silly_mean.timet'] = timt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_save_results(results, filename='final-results.csv'):\n",
    "    '''\n",
    "    function to print and export modelling results\n",
    "    '''\n",
    "    display(pd.DataFrame.from_dict(results).T)\n",
    "    print(pd.DataFrame.from_dict(results).T.to_latex())\n",
    "    pd.DataFrame.from_dict(results).T.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>silly_mean.rmse</th>\n",
       "      <th>silly_mean.timt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>0.027263</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rus_stackoverflow</th>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflow</th>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superuser</th>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   silly_mean.rmse  silly_mean.timt\n",
       "english                   0.020986             0.70\n",
       "math                      0.027263             1.31\n",
       "rus_stackoverflow         0.023957             0.56\n",
       "stackoverflow             0.022020             0.61\n",
       "superuser                 0.020280             0.66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  silly\\_mean.rmse &  silly\\_mean.timt \\\\\n",
      "\\midrule\n",
      "english           &         0.020986 &             0.70 \\\\\n",
      "math              &         0.027263 &             1.31 \\\\\n",
      "rus\\_stackoverflow &         0.023957 &             0.56 \\\\\n",
      "stackoverflow     &         0.022020 &             0.61 \\\\\n",
      "superuser         &         0.020280 &             0.66 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewcount Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[94menglish's\u001b[0m\u001b[92m viewcount\u001b[0m model is 0.020949\n",
      "The root-mean-square error of \u001b[94mmath's\u001b[0m\u001b[92m viewcount\u001b[0m model is 0.027226\n",
      "The root-mean-square error of \u001b[94mrus_stackoverflow's\u001b[0m\u001b[92m viewcount\u001b[0m model is 0.023914\n",
      "The root-mean-square error of \u001b[94mstackoverflow's\u001b[0m\u001b[92m viewcount\u001b[0m model is 0.022019\n",
      "The root-mean-square error of \u001b[94msuperuser's\u001b[0m\u001b[92m viewcount\u001b[0m model is 0.020267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>silly_mean.rmse</th>\n",
       "      <th>silly_mean.timt</th>\n",
       "      <th>viewcount.impr</th>\n",
       "      <th>viewcount.rmse</th>\n",
       "      <th>viewcount.timt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>0.027263</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>67.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rus_stackoverflow</th>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.023914</td>\n",
       "      <td>21.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflow</th>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>30.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superuser</th>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>24.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   silly_mean.rmse  silly_mean.timt  viewcount.impr  \\\n",
       "english                   0.020986             0.70           0.176   \n",
       "math                      0.027263             1.31           0.136   \n",
       "rus_stackoverflow         0.023957             0.56           0.179   \n",
       "stackoverflow             0.022020             0.61           0.005   \n",
       "superuser                 0.020280             0.66           0.064   \n",
       "\n",
       "                   viewcount.rmse  viewcount.timt  \n",
       "english                  0.020949           15.55  \n",
       "math                     0.027226           67.35  \n",
       "rus_stackoverflow        0.023914           21.53  \n",
       "stackoverflow            0.022019           30.33  \n",
       "superuser                0.020267           24.89  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  silly\\_mean.rmse &  silly\\_mean.timt &  viewcount.impr &  viewcount.rmse &  viewcount.timt \\\\\n",
      "\\midrule\n",
      "english           &         0.020986 &             0.70 &           0.176 &        0.020949 &           15.55 \\\\\n",
      "math              &         0.027263 &             1.31 &           0.136 &        0.027226 &           67.35 \\\\\n",
      "rus\\_stackoverflow &         0.023957 &             0.56 &           0.179 &        0.023914 &           21.53 \\\\\n",
      "stackoverflow     &         0.022020 &             0.61 &           0.005 &        0.022019 &           30.33 \\\\\n",
      "superuser         &         0.020280 &             0.66 &           0.064 &        0.020267 &           24.89 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 1.21 s, sys: 353 ms, total: 1.56 s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#3min 56s\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'y_ravi'\n",
    "numic_variables = ['viewcount']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression on just viewcount\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100, # this doesn't change anything\n",
    "                      #regParam=0.3, # using regularisation parameter here useless since there is one feature\n",
    "                      #elasticNetParam=0.8,\n",
    "                      featuresCol=\"features\",\n",
    "                      labelCol=target,\n",
    "                      predictionCol=\"viewcount_pred\")\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "#.addGrid(lr.regParam, [1e-3, 1.])\n",
    "#.addGrid(lr.elasticNetParam, [1e-3, 1.])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"y_ravi\", predictionCol=\"viewcount_pred\")\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## this fits on train, then predicts on test\n",
    "    rmse = round( evaluator.evaluate(crossval.fit(train[i]).transform(test[i])), 6)\n",
    "    \n",
    "    ''' CODE TO USE LATER\n",
    "    cvModel = final_pipeline.fit(datasets[i])\n",
    "    cvModel.avgMetrics\n",
    "    list(zip(cvModel.avgMetrics, paramGrid))\n",
    "    cvModel.bestModel.stages\n",
    "    cvModel.bestModel.stages[1].extractParamMap()\n",
    "    '''\n",
    "        \n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m viewcount\\033[0m model is {rmse}\")\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 3 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timt = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i]['viewcount.rmse'] = rmse\n",
    "    RESULTS[i]['viewcount.v.imprv'] = impr\n",
    "    RESULTS[i]['viewcount.timet'] = timt\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS, 'test-set-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interesting that there are different improvements of viewcount over mean-only prediciton\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## garbage collector to speed up computation\n",
    "import gc\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define features available at time of submitting question\n",
    "target = \"y_ravi\"\n",
    "indep_text_variables = [\"title\", \"clean_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import elements from natural language toolkit\n",
    "import nltk\n",
    "#nltk.download('all') # uncomment after first run as admin check\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def get_tokens(line):\n",
    "    '''\n",
    "    Function to parse text features\n",
    "    '''\n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuations from each word\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # lemmatizing the words, see https://en.wikipedia.org/wiki/Lemmatisation\n",
    "    '''lemmatise or stem???'''\n",
    "    words = [lmtzr.lemmatize(w) for w in words]\n",
    "    # remove single letters\n",
    "    words = [word for word in words if not len(word)==1]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "## custom transformer for nltk tokenisation\n",
    "\n",
    "class NLTKWordPunctTokenizer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        super(NLTKWordPunctTokenizer, self).__init__()\n",
    "        self.stopwords = Param(self, \"stopwords\", \"\")\n",
    "        self._setDefault(stopwords=set())\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None, stopwords=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setStopwords(self, value):\n",
    "        self._paramMap[self.stopwords] = value\n",
    "        return self\n",
    "\n",
    "    def getStopwords(self):\n",
    "        return self.getOrDefault(self.stopwords)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        stopwords = self.getStopwords()\n",
    "\n",
    "        def f(s):\n",
    "            tokens = nltk.tokenize.wordpunct_tokenize(s)\n",
    "            return [t for t in tokens if t.lower() not in stopwords]\n",
    "\n",
    "        t = ArrayType(StringType())\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "\n",
    "## custom transformer to spread sparse vectors into individual columns\n",
    "class VectorMLliber(Transformer):\n",
    "    \"\"\"\n",
    "    A custom Transformer which converts a column of pyspark.ml vectors to multiple pyspark.mllib vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputCol=None):\n",
    "        super(VectorMLliber, self).__init__()\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        def f(v):\n",
    "            return Vectors.sparse(v.size, v.indices, v.values)\n",
    "        \n",
    "        df = df.rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)\n",
    "\n",
    "features = {}\n",
    "feature_vec_list = {}\n",
    "for i in data_array:\n",
    "    features[i] = word_feat_list[i].select(\"features\")\n",
    "    feature_vec_list[i] = features[i].rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "    feature_vec_list[i].cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenizer_body = NLTKWordPunctTokenizer(\n",
    "    inputCol=\"clean_body\", outputCol=\"body_words\",  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokenizer_title = NLTKWordPunctTokenizer(\n",
    "    inputCol=\"title\", outputCol=\"title_words\",  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, VectorAssembler\n",
    "\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol=\"body_words\", outputCol=\"body_features\", minDF=2)\n",
    "\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol=\"title_words\", outputCol=\"title_features\", minDF=2)\n",
    "\n",
    "VectorMLliber_body = VectorMLliber(inputCol=\"body_features\")\n",
    "\n",
    "VectorMLliber_title = VectorMLliber(inputCol=\"body_title\")\n",
    "\n",
    "\n",
    "\n",
    "processing_pipeline = Pipeline(stages=[\n",
    "    nltk_tokenizer_body, \n",
    "    nltk_tokenizer_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## check that pipeline is working (WHICH IT IS NOT)\n",
    "\n",
    "data_processed = processing_pipeline.fit(datasets['english']).transform(datasets['english'])\n",
    "\n",
    "show_spark_df(data_processed)\n",
    "\n",
    "#data_processed.head(2)[0].features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_ensembler = VectorAssembler(inputCols=[\"body_features\", \"title_features\"], \n",
    "                                         outputCol=\"features\")  \n",
    "\n",
    "processing_pipeline = Pipeline(stages=[processing_pipeline, processing_ensembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=100,\n",
    "                      regParam=0.3,\n",
    "                      elasticNetParam=0.8,\n",
    "                      featuresCol=\"features\",\n",
    "                      labelCol=\"y_ravi\",\n",
    "                      predictionCol=\"prediction\")\n",
    "\n",
    "# fit linear regression pipeline\n",
    "pipeline = Pipeline(stages=[processing_pipeline, lr])\n",
    "trained_pipeline = pipeline.fit(datasets['english'])\n",
    "trained_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_spark_df(trained_pipeline.transform(datasets['english']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trained_pipeline\n",
    " .transform(datasets['english'])\n",
    " .select(\n",
    "    indep_text_variables + [\"prediction\"]\n",
    " )\n",
    " .write\n",
    " .parquet(\"linreg_prediction.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions = spark.read.parquet(\"linreg_prediction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.select(\"prediction\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(estimator_pipeline, 'pipeline.joblib') \n",
    "\n",
    "reloaded = load(\"pipeline.joblib\")\n",
    "\n",
    "Now we can predict directly!\n",
    "\n",
    "reloaded.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 0-master-notebook-pipelines.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
