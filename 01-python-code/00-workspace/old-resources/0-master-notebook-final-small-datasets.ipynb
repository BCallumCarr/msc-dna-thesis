{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Welcome to my PySpark analysis of some StackExchange Data\"\\n'\n"
     ]
    }
   ],
   "source": [
    "## testing printing output from console\n",
    "import subprocess\n",
    "\n",
    "cmd = [ 'echo', '\"Welcome to my PySpark analysis of some StackExchange Data\"' ]\n",
    "output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc #garbage collection\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spark UI, version 2.4.3, is available at: http://192.168.0.26:4040/ and the defaultParallelism is 4\n"
     ]
    }
   ],
   "source": [
    "%run -i '1-load-pyspark.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load easyFunctions and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## easy functions\n",
    "%run -i 'load_parquet_data.py'\n",
    "%run -i 'convert_csv_to_pyarrow_parquet.py'\n",
    "%run -i 'export_parquet_data.py'\n",
    "%run -i 'count_total_questions.py'\n",
    "%run -i 'show_save_results.py'\n",
    "%run -i 'show_spark_df.py'\n",
    "%run -i 'show_date_range.py'\n",
    "%run -i 'trim_betw_dates.py'\n",
    "\n",
    "## pipeline transformers\n",
    "%run -i 'nltkWordPunctTokeniser.py'\n",
    "%run -i 'nltkSenteniser.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## these are the forum labels that will appear in graphs/tables etc.\n",
    "data_array = [\n",
    "    #'Buddhism',\n",
    "    #'Economics',\n",
    "    #'Fitness',\n",
    "    #'Health',\n",
    "    #'Interpersonal'\n",
    "    'Stats',\n",
    "    'English',\n",
    "    #'Math',\n",
    "    #'Superuser',\n",
    "    #'Stackoverflow',\n",
    " \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call download script - EDIT to feed in user data_array\n",
    "#!bash 0-dataset-download.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## for stackoverflow\n",
    "#convert_csv_to_pyarrow_parquet(str_dir='initial-data/stackoverflow.stackexchange.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop through data_array\n",
    "#for i in data_array:\n",
    "#    s = i.lower()\n",
    "#    !python convert-xml-to-parquet.py \"$s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Initial or Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:09:33.031151\n",
      "CPU times: user 3.24 ms, sys: 2.4 ms, total: 5.65 ms\n",
      "Wall time: 3.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "datasets = load_parquet_data(dataArray=data_array, kind='clean', printSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join Stack Overflow datasets\n",
    "#union1 = temp1.union(temp2)\n",
    "#union2 = union1.union(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats: 139302\n",
      "English: 105475\n",
      "\n",
      "Total: 244777\n"
     ]
    }
   ],
   "source": [
    "## count questions before trimming\n",
    "count_total_questions(dataArray=data_array, datasetDict=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Trim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:15:06.880047\n",
      "\n",
      "\u001b[1m checking columns are the right types and names \u001b[0m\n",
      "\n",
      "----- Stats -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "----- English -----\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- viewcount: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- clean_date: timestamp (nullable = true)\n",
      " |-- clean_body: string (nullable = true)\n",
      "\n",
      "None\n",
      "\n",
      "\u001b[1m checking that there are no nans \u001b[0m\n",
      "\n",
      "----- Stats -----\n",
      "+-----+---------+-----+----------+\n",
      "|title|viewcount|score|clean_body|\n",
      "+-----+---------+-----+----------+\n",
      "|    0|        0|    0|         0|\n",
      "+-----+---------+-----+----------+\n",
      "\n",
      "----- English -----\n",
      "+-----+---------+-----+----------+\n",
      "|title|viewcount|score|clean_body|\n",
      "+-----+---------+-----+----------+\n",
      "|    0|        0|    0|         0|\n",
      "+-----+---------+-----+----------+\n",
      "\n",
      "CPU times: user 46.5 ms, sys: 12.8 ms, total: 59.2 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '2-clean-datasets.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "2009-02-02 14:21:12.103000\n",
      "2019-06-02 04:19:33.143000\n",
      "\n",
      "English:\n",
      "2009-06-16 13:06:53.033000\n",
      "2019-06-02 04:02:54.070000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## show range of dates for datasets before trimming\n",
    "show_date_range(dataArray=data_array, datasetDict=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trim data between uniform date range\n",
    "datasets = trim_betw_dates(dataArray=data_array, datasetDict=datasets, dates=('2010-09-01', '2011-09-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "2011-09-01 00:11:37.547000\n",
      "2012-08-31 21:04:31.477000\n",
      "\n",
      "English:\n",
      "2011-09-01 00:27:46.723000\n",
      "2012-08-31 22:10:29.680000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## show range of dates for datasets after trimming\n",
    "show_date_range(dataArray=data_array, datasetDict=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats: 7134\n",
      "English: 8433\n",
      "\n",
      "Total: 15567\n"
     ]
    }
   ],
   "source": [
    "## count questions after trimming\n",
    "count_total_questions(dataArray=data_array, datasetDict=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts and LDA Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:16:13.405301\n",
      "On to Stats\n",
      "On to English\n",
      "On to Stats\n",
      "On to English\n",
      "CPU times: user 638 ms, sys: 199 ms, total: 836 ms\n",
      "Wall time: 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# about 23 min with 10 iterations and params\n",
    "# FAILS for large datasets\n",
    "print(datetime.now().time())\n",
    "%run -i '3-feat-engineering.py'\n",
    "\n",
    "###\n",
    "# TRY different values of alpha and rho\n",
    "# TRY different values of K\n",
    "# TRY 'em' optimizer instead of 'online'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:26:28.199294\n",
      "On to Stats\n",
      "On to English\n",
      "CPU times: user 35.1 ms, sys: 27 ms, total: 62.1 ms\n",
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# about 8 min\n",
    "print(datetime.now().time())\n",
    "export_parquet_data(dataArray=data_array, datasetDict=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:52:44.845519\n",
      "\n",
      "\u001b[1mCorrelations between score and viewcount\u001b[0m\n",
      "\n",
      "Stats & 0.63 \\\\\n",
      "English & 0.36 \\\\\n",
      "\n",
      "\u001b[1mViewcount\u001b[0m descriptives\n",
      "\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "0 &  count &      mean &   stddev &  min &      max \\\\\n",
      "\\midrule\n",
      "Stats   &   4068 &   7589.14 &  27225.7 &   30 &   641120 \\\\\n",
      "English &   8537 &  25154.98 &  66872.7 &   48 &  1827972 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\u001b[1mScore\u001b[0m descriptives\n",
      "\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "0 &  count &  mean &  stddev &  min &  max \\\\\n",
      "\\midrule\n",
      "Stats   &   4068 &  9.71 &   23.45 &   -3 &  925 \\\\\n",
      "English &   8537 &  8.82 &   15.26 &   -9 &  581 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\u001b[1mviewcount\u001b[0m\n",
      "\n",
      "\u001b[1mscore\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brad/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n",
      "/Users/brad/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrl}\n",
      "\\toprule\n",
      "{} &  score &  viewcount &                                                                     title \\\\\n",
      "\\midrule\n",
      "0 &    925 &     535531 &  Making sense of principal component analysis, eigenvectors \\& eigenvalues \\\\\n",
      "0 &     -3 &        163 &                                             How to get the required data? \\\\\n",
      "1 &     -3 &        773 &                                Distribution of a ratio of two proportions \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrl}\n",
      "\\toprule\n",
      "{} &  score &  viewcount &                                                                title \\\\\n",
      "\\midrule\n",
      "0 &    581 &      44658 &         How do you quote a passage that has used '[sic]' mistakenly? \\\\\n",
      "0 &     -9 &        441 &  How to comprehend the phrase \"put them in affluent group of people\" \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 3.07 s, sys: 126 ms, total: 3.2 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '4-final-eda.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 14 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:11:58.906233\n",
      "\n",
      "Standard deviations are:\n",
      "\n",
      "Stats & 15.86 & 12.2 & -23.08 \\\\\n",
      "English & 7.6 & 7.78 & 2.37 \\\\\n",
      "CPU times: user 40.8 ms, sys: 12.2 ms, total: 53 ms\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "%run -i '6a-rand-train-test-split-50.py'\n",
    "#%run -i '6b-time-train-test-split-50.py'\n",
    "\n",
    "## check standard deviations of variables\n",
    "print('\\nStandard deviations are:\\n')\n",
    "for i in data_array:\n",
    "    tr = round( pd.to_numeric(train[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )\n",
    "    te = round( pd.to_numeric(test[i].describe('score').select('score').toPandas().iloc[2][0]), 2 )\n",
    "    perc = round( (te/tr - 1)*100, 2 )\n",
    "    s = i.title() + ' & ' + str(tr) + ' & ' + str(te) + ' & ' + str(perc) + ' \\\\\\\\'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 245 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninteresting to see how skewed rus_stackoverflow posts are to more posts in recent years\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "interesting to see how skewed rus_stackoverflow posts are to more posts in recent years\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silly Mean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root-mean-square error of \u001b[94mStats's\u001b[0m\u001b[92m mean\u001b[0m model is 12.2\n",
      "The root-mean-square error of \u001b[94mEnglish's\u001b[0m\u001b[92m mean\u001b[0m model is 7.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0silly_mean.0tr_rmse</th>\n",
       "      <th>0silly_mean.1rmse</th>\n",
       "      <th>0silly_mean.2timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>15.85</td>\n",
       "      <td>12.20</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>7.60</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0silly_mean.0tr_rmse  0silly_mean.1rmse  0silly_mean.2timet\n",
       "Stats                   15.85              12.20                1.26\n",
       "English                  7.60               7.78                0.89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  0silly\\_mean.0tr\\_rmse &  0silly\\_mean.1rmse &  0silly\\_mean.2timet \\\\\n",
      "\\midrule\n",
      "Stats   &                 15.85 &              12.20 &                1.26 \\\\\n",
      "English &                  7.60 &               7.78 &                0.89 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "## choose target variable\n",
    "target = 'score'\n",
    "\n",
    "## create mean dictionaries\n",
    "y_ravi_tr_means = {}\n",
    "\n",
    "## calculate the mean of each forum, using ONLY training set\n",
    "for i in data_array:\n",
    "    y_ravi_tr_means[i] = train[i].select(target).rdd.flatMap(lambda x: x).mean()\n",
    "\n",
    "## import rmse evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "## create dictionaries for training and testing (baseline) rmse \n",
    "base = {}\n",
    "tr_rmse = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "\n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## train silly mean model by assigning training set mean for training and testing predictions\n",
    "    train[i] = train[i].withColumn('mean_pred', F.lit(y_ravi_tr_means[i]))\n",
    "    test[i] = test[i].withColumn('mean_pred', F.lit(y_ravi_tr_means[i]))\n",
    "\n",
    "    ## evaluate silly mean model, on both training and testing set\n",
    "    evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='mean_pred')\n",
    "    tr_rmse[i] = round( evaluator.evaluate(train[i]), 2)\n",
    "    base[i] = round( evaluator.evaluate(test[i]), 2)\n",
    "\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m mean\\033[0m model is {base[i]}\")\n",
    "\n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "    \n",
    "    ## store as dictionary inside RESULTS dictionary, initiating dataset name entries first\n",
    "    RESULTS[i.title()]['0silly_mean.0tr_rmse'] = tr_rmse[i]\n",
    "    RESULTS[i.title()]['0silly_mean.1rmse'] = base[i]\n",
    "    RESULTS[i.title()]['0silly_mean.2timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewcount Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:12:41.069154\n",
      "The root-mean-square error of \u001b[94mStats's\u001b[0m\u001b[92m viewcount\u001b[0m model is 10.12\n",
      "The root-mean-square error of \u001b[94mEnglish's\u001b[0m\u001b[92m viewcount\u001b[0m model is 7.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1viewcount.0tr_rmse</th>\n",
       "      <th>1viewcount.1rmse</th>\n",
       "      <th>1viewcount.2imprv</th>\n",
       "      <th>1viewcount.3timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>11.20</td>\n",
       "      <td>10.12</td>\n",
       "      <td>17.05</td>\n",
       "      <td>11.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>6.87</td>\n",
       "      <td>7.01</td>\n",
       "      <td>9.90</td>\n",
       "      <td>8.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1viewcount.0tr_rmse  1viewcount.1rmse  1viewcount.2imprv  \\\n",
       "Stats                  11.20             10.12              17.05   \n",
       "English                 6.87              7.01               9.90   \n",
       "\n",
       "         1viewcount.3timet  \n",
       "Stats                11.85  \n",
       "English               8.68  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  1viewcount.0tr\\_rmse &  1viewcount.1rmse &  1viewcount.2imprv &  1viewcount.3timet \\\\\n",
      "\\midrule\n",
      "Stats   &                11.20 &             10.12 &              17.05 &              11.85 \\\\\n",
      "English &                 6.87 &              7.01 &               9.90 &               8.68 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 653 ms, sys: 158 ms, total: 811 ms\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['viewcount']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression on just viewcount\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100, # this doesn't change anything\n",
    "                      #regParam=0.3, # using regularisation parameter here useless since there is one feature\n",
    "                      #elasticNetParam=0.8,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='viewcount_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='viewcount_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    \n",
    "    ## fitting on train and predicting on train/test\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "        \n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m viewcount\\033[0m model is {rmse}\")\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['1viewcount.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['1viewcount.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['1viewcount.2imprv'] = impr\n",
    "    RESULTS[i.title()]['1viewcount.3timet'] = timet\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInteresting that there are different improvements of viewcount over mean-only prediciton\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Interesting that there are different improvements of viewcount over mean-only prediciton\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 979 objects.\n"
     ]
    }
   ],
   "source": [
    "## garbage collector to speed up computation\n",
    "collected = gc.collect()\n",
    "print(f'Garbage collector: collected {collected} objects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:13:01.896365\n",
      "The root-mean-square error of \u001b[94mStats's\u001b[0m\u001b[92m counts\u001b[0m model is 12.2\n",
      "The root-mean-square error of \u001b[94mEnglish's\u001b[0m\u001b[92m counts\u001b[0m model is 7.76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2counts.0tr_rmse</th>\n",
       "      <th>2counts.1rmse</th>\n",
       "      <th>2counts.2imprv</th>\n",
       "      <th>2counts.3timet</th>\n",
       "      <th>2counts.4elastic</th>\n",
       "      <th>2counts.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>15.85</td>\n",
       "      <td>12.20</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>12.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>7.57</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         2counts.0tr_rmse  2counts.1rmse  2counts.2imprv  2counts.3timet  \\\n",
       "Stats               15.85          12.20           -0.00           12.64   \n",
       "English              7.57           7.76            0.26           12.78   \n",
       "\n",
       "         2counts.4elastic  2counts.5regular  \n",
       "Stats                1.00               1.0  \n",
       "English              0.01               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  2counts.0tr\\_rmse &  2counts.1rmse &  2counts.2imprv &  2counts.3timet &  2counts.4elastic &  2counts.5regular \\\\\n",
      "\\midrule\n",
      "Stats   &             15.85 &          12.20 &           -0.00 &           12.64 &              1.00 &               1.0 \\\\\n",
      "English &              7.57 &           7.76 &            0.26 &           12.78 &              0.01 &               1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 1.96 s, sys: 539 ms, total: 2.5 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['body_word_cnt', 'titl_word_cnt', 'body_char_cnt', \n",
    "                   'titl_char_cnt', 'body_sent_cnt', 'titl_sent_cnt']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## NUMERICAL columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## create PROCESSING pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100,\n",
    "                      #regParam=1,\n",
    "                      #elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='counts_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-2, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-2, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='counts_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m counts\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2counts.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2counts.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2counts.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2counts.3timet'] = timet\n",
    "    RESULTS[i.title()]['2counts.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2counts.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:13:27.483763\n",
      "The root-mean-square error of \u001b[94mStats's\u001b[0m\u001b[92m tokens\u001b[0m model is 13.75\n",
      "The root-mean-square error of \u001b[94mEnglish's\u001b[0m\u001b[92m tokens\u001b[0m model is 7.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2tokens.0tr_rmse</th>\n",
       "      <th>2tokens.1rmse</th>\n",
       "      <th>2tokens.2imprv</th>\n",
       "      <th>2tokens.3timet</th>\n",
       "      <th>2tokens.4elastic</th>\n",
       "      <th>2tokens.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>12.53</td>\n",
       "      <td>13.75</td>\n",
       "      <td>-12.70</td>\n",
       "      <td>444.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>7.29</td>\n",
       "      <td>7.81</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>270.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         2tokens.0tr_rmse  2tokens.1rmse  2tokens.2imprv  2tokens.3timet  \\\n",
       "Stats               12.53          13.75          -12.70          444.63   \n",
       "English              7.29           7.81           -0.39          270.41   \n",
       "\n",
       "         2tokens.4elastic  2tokens.5regular  \n",
       "Stats                 1.0               1.0  \n",
       "English               1.0               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  2tokens.0tr\\_rmse &  2tokens.1rmse &  2tokens.2imprv &  2tokens.3timet &  2tokens.4elastic &  2tokens.5regular \\\\\n",
      "\\midrule\n",
      "Stats   &             12.53 &          13.75 &          -12.70 &          444.63 &               1.0 &               1.0 \\\\\n",
      "English &              7.29 &           7.81 &           -0.39 &          270.41 &               1.0 &               1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 3.42 s, sys: 908 ms, total: 4.32 s\n",
      "Wall time: 11min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "# 18min 32s for 2-CV and GRIDSEARCH\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "textt_variables = ['title', 'clean_body']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## textual columns\n",
    "# tokenising text cols with custom transformer\n",
    "nltk_tokeniser_body = nltkWordPunctTokeniser(\n",
    "    inputCol='clean_body', outputCol='body_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "nltk_tokeniser_title = nltkWordPunctTokeniser(\n",
    "    inputCol='title', outputCol='titl_words',  \n",
    "    stopwords=set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "# count occurence of tokens, i.e. create dfm\n",
    "cnt_vectrizr_body = CountVectorizer(inputCol='body_words', outputCol='body_raw_feats') #!!! minDF???\n",
    "cnt_vectrizr_title = CountVectorizer(inputCol='titl_words', outputCol='titl_raw_feats')\n",
    "\n",
    "# create IDF dfm\n",
    "idf_body = IDF(inputCol=\"body_raw_feats\", outputCol=\"body_feats\")\n",
    "idf_title = IDF(inputCol=\"titl_raw_feats\", outputCol=\"titl_feats\")\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['body_feats', 'titl_feats'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    nltk_tokeniser_body, \n",
    "    nltk_tokeniser_title,\n",
    "    cnt_vectrizr_body,\n",
    "    cnt_vectrizr_title,\n",
    "    idf_body,\n",
    "    idf_title,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100,\n",
    "                      #regParam=1,\n",
    "                      #elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='tokens_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-2, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-2, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='tokens_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m tokens\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2tokens.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2tokens.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2tokens.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2tokens.3timet'] = timet\n",
    "    RESULTS[i.title()]['2tokens.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2tokens.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keys\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tokens_pred=5.784398301735584),\n",
       " Row(tokens_pred=5.589520238592335),\n",
       " Row(tokens_pred=5.496234454981099),\n",
       " Row(tokens_pred=13.296713465267583),\n",
       " Row(tokens_pred=6.625309919268257),\n",
       " Row(tokens_pred=8.265681426752378),\n",
       " Row(tokens_pred=5.496234454981099),\n",
       " Row(tokens_pred=5.6869592701639595),\n",
       " Row(tokens_pred=5.496234454981099),\n",
       " Row(tokens_pred=5.496234454981099)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check predictions aren't constant\n",
    "models[data_array[0]].transform(test[data_array[0]]).select('tokens_pred').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it's the number of questions in the data\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"why the heck does everything besides interpersonal have constant predictions - it's not the parameters or the size of the data\"\"\"\n",
    "\"\"\"it's the number of questions in the data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Features Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:25:25.727229\n",
      "The root-mean-square error of \u001b[94mStats's\u001b[0m\u001b[92m topics\u001b[0m model is 12.19\n",
      "The root-mean-square error of \u001b[94mEnglish's\u001b[0m\u001b[92m topics\u001b[0m model is 7.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2topics.0tr_rmse</th>\n",
       "      <th>2topics.1rmse</th>\n",
       "      <th>2topics.2imprv</th>\n",
       "      <th>2topics.3timet</th>\n",
       "      <th>2topics.4elastic</th>\n",
       "      <th>2topics.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>15.84</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>7.60</td>\n",
       "      <td>7.78</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         2topics.0tr_rmse  2topics.1rmse  2topics.2imprv  2topics.3timet  \\\n",
       "Stats               15.84          12.19            0.08            9.13   \n",
       "English              7.60           7.78           -0.00            8.12   \n",
       "\n",
       "         2topics.4elastic  2topics.5regular  \n",
       "Stats                 1.0               1.0  \n",
       "English               1.0               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  2topics.0tr\\_rmse &  2topics.1rmse &  2topics.2imprv &  2topics.3timet &  2topics.4elastic &  2topics.5regular \\\\\n",
      "\\midrule\n",
      "Stats   &             15.84 &          12.19 &            0.08 &            9.13 &               1.0 &               1.0 \\\\\n",
      "English &              7.60 &           7.78 &           -0.00 &            8.12 &               1.0 &               1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 1.51 s, sys: 423 ms, total: 1.93 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['btd[0]', 'btd[1]', 'btd[2]', 'btd[3]', 'btd[4]', \n",
    "                   'btd[5]', 'btd[6]', 'btd[7]', 'btd[8]', 'btd[9]', \n",
    "                   'std[0]', 'std[1]', 'std[2]', 'std[3]', 'std[4]', \n",
    "                   'std[5]', 'std[6]', 'std[7]', 'std[8]', 'std[9]',\n",
    "                   'ttd[0]', 'ttd[1]', 'ttd[2]', 'ttd[3]', 'ttd[4]', \n",
    "                   'ttd[5]', 'ttd[6]', 'ttd[7]', 'ttd[8]', 'ttd[9]'] \n",
    "\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "'''## date columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')'''\n",
    "\n",
    "## numerical columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "## create processing pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[numic_pipeline, process_assembler])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100,\n",
    "                      #regParam=1,\n",
    "                      #elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='topics_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-2, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-2, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='topics_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m topics\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['2topics.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['2topics.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['2topics.2imprv'] = impr\n",
    "    RESULTS[i.title()]['2topics.3timet'] = timet\n",
    "    RESULTS[i.title()]['2topics.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['2topics.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for i in data_array:\n",
    "    # capitalise keysa\n",
    "    RESULTS[i.title()] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:25:43.087606\n",
      "The root-mean-square error of \u001b[94mStats's\u001b[0m\u001b[92m final\u001b[0m model is 12.19\n",
      "The root-mean-square error of \u001b[94mEnglish's\u001b[0m\u001b[92m final\u001b[0m model is 7.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3final.0tr_rmse</th>\n",
       "      <th>3final.1rmse</th>\n",
       "      <th>3final.2imprv</th>\n",
       "      <th>3final.3timet</th>\n",
       "      <th>3final.4elastic</th>\n",
       "      <th>3final.5regular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>15.84</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>7.60</td>\n",
       "      <td>7.78</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         3final.0tr_rmse  3final.1rmse  3final.2imprv  3final.3timet  \\\n",
       "Stats              15.84         12.19           0.08           9.16   \n",
       "English             7.60          7.78          -0.00           8.27   \n",
       "\n",
       "         3final.4elastic  3final.5regular  \n",
       "Stats                1.0              1.0  \n",
       "English              1.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  3final.0tr\\_rmse &  3final.1rmse &  3final.2imprv &  3final.3timet &  3final.4elastic &  3final.5regular \\\\\n",
      "\\midrule\n",
      "Stats   &            15.84 &         12.19 &           0.08 &           9.16 &              1.0 &              1.0 \\\\\n",
      "English &             7.60 &          7.78 &          -0.00 &           8.27 &              1.0 &              1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "CPU times: user 1.56 s, sys: 435 ms, total: 2 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now().time())\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StandardScaler, VectorAssembler, VectorSlicer\n",
    "\n",
    "########################\n",
    "##### CHOOSE FEATS ##### can't get date right\n",
    "########################\n",
    "\n",
    "## define features to predict on\n",
    "target = 'score'\n",
    "numic_variables = ['btd[0]', 'btd[1]', 'btd[2]', 'btd[3]', 'btd[4]', \n",
    "                   'btd[5]', 'btd[6]', 'btd[7]', 'btd[8]', 'btd[9]', \n",
    "                   'std[0]', 'std[1]', 'std[2]', 'std[3]', 'std[4]', \n",
    "                   'std[5]', 'std[6]', 'std[7]', 'std[8]', 'std[9]',\n",
    "                   'ttd[0]', 'ttd[1]', 'ttd[2]', 'ttd[3]', 'ttd[4]', \n",
    "                   'ttd[5]', 'ttd[6]', 'ttd[7]', 'ttd[8]', 'ttd[9]',\n",
    "                   'body_word_cnt', 'titl_word_cnt', 'body_char_cnt', \n",
    "                   'titl_char_cnt', 'body_sent_cnt', 'titl_sent_cnt']\n",
    "datet_variables = ['clean_date']\n",
    "\n",
    "### DATE columns\n",
    "datet_assembler = VectorAssembler(inputCols=datet_variables, outputCol='datet_data')\n",
    "\n",
    "### NUMERICAL columns\n",
    "numic_assembler = VectorAssembler(inputCols=numic_variables, outputCol='numic_data') # have to put in single col\n",
    "standardiser = StandardScaler(inputCol='numic_data', outputCol='numic_data_std')    \n",
    "numic_pipeline = Pipeline(stages=[numic_assembler, standardiser])\n",
    "\n",
    "\n",
    "## create PROCESSING pipeline\n",
    "process_assembler = VectorAssembler(inputCols=['numic_data'], #inputCols=['datet_data']\n",
    "                                    outputCol='features') \n",
    "process_pipeline = Pipeline(stages=[  #inputCols=['datet_data']\n",
    "    numic_pipeline,\n",
    "    process_assembler\n",
    "])\n",
    "\n",
    "########################\n",
    "##### CHOOSE MODEL #####\n",
    "########################\n",
    "\n",
    "## linear regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "lr = LinearRegression(#maxIter=100,\n",
    "                      #regParam=1,\n",
    "                      #elasticNetParam=1,\n",
    "                      featuresCol='features',\n",
    "                      labelCol=target,\n",
    "                      predictionCol='finalm_pred')\n",
    "\n",
    "## make final pipeline\n",
    "final_pipeline = Pipeline(stages=[process_pipeline, lr])\n",
    "\n",
    "## import methods for tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "## set up grid for parameter tuning: \n",
    "'''NEEDED, BUT IMMENSELY SLOWING DOWN'''\n",
    "# Ravi et al use L2, aka ridge, aka elasticNetParam=0\n",
    "# regParam is the value of lambda\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1e-2, 1.]) \\\n",
    "    .addGrid(lr.regParam, [1e-2, 1.]) \\\n",
    "    .build()\n",
    "\n",
    "## set up rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol=target, predictionCol='finalm_pred')\n",
    "\n",
    "## set up cross validation for parameter tuning\n",
    "'''DEFINITELY SLOWING DOWN'''\n",
    "crossval = CrossValidator(estimator=final_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "## create models dict\n",
    "models = {}\n",
    "\n",
    "## modelling\n",
    "for i in data_array:\n",
    "    \n",
    "    ## initial variable for timing\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ## fit on training set with CV\n",
    "    cvmodel = crossval.fit(train[i])\n",
    "    models[i] = cvmodel\n",
    "    \n",
    "    ## predict and evaluate\n",
    "    tr_rmse = round( evaluator.evaluate(cvmodel.transform(train[i])), 2 )\n",
    "    rmse = round( evaluator.evaluate(cvmodel.transform(test[i])), 2 )\n",
    "    print(f\"The root-mean-square error of \\033[94m{i}'s\\033[0m\\033[92m final\\033[0m model is {rmse}\")\n",
    "    \n",
    "    ## get params\n",
    "    # elasticnet\n",
    "    ela_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[1]\n",
    "    ela_param = cvmodel.bestModel.stages[-1].extractParamMap()[ela_key]\n",
    "    # reg'sation\n",
    "    reg_key = list(cvmodel.bestModel.stages[-1].extractParamMap().keys())[9]\n",
    "    reg_param = cvmodel.bestModel.stages[-1].extractParamMap()[reg_key]\n",
    "\n",
    "    ## calculate improvement over median baseline\n",
    "    impr = round( (rmse/base[i] - 1)*-100, 2 )\n",
    "    \n",
    "    ## record time taken\n",
    "    timet = round( time.time() - t0, 2 )\n",
    "\n",
    "    ## store as dictionary inside RESULTS dictionary\n",
    "    RESULTS[i.title()]['3final.0tr_rmse'] = tr_rmse\n",
    "    RESULTS[i.title()]['3final.1rmse'] = rmse\n",
    "    RESULTS[i.title()]['3final.2imprv'] = impr\n",
    "    RESULTS[i.title()]['3final.3timet'] = timet\n",
    "    RESULTS[i.title()]['3final.4elastic'] = ela_param\n",
    "    RESULTS[i.title()]['3final.5regular'] = reg_param\n",
    "    \n",
    "## record results\n",
    "show_save_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(finalm_pred=6.361150704095528),\n",
       " Row(finalm_pred=6.486751918831093),\n",
       " Row(finalm_pred=6.5020183317054325),\n",
       " Row(finalm_pred=6.332715831420088),\n",
       " Row(finalm_pred=6.396022661404337),\n",
       " Row(finalm_pred=6.504573459336636),\n",
       " Row(finalm_pred=6.378045727212639),\n",
       " Row(finalm_pred=6.345291775885759),\n",
       " Row(finalm_pred=6.322897788846911),\n",
       " Row(finalm_pred=6.416152443848872)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check predictions aren't constant\n",
    "models[data_array[0]].transform(test[data_array[0]]).select('finalm_pred').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trained_pipeline\n",
    " .transform(datasets['english'])\n",
    " .select(\n",
    "    indep_text_variables + [\"prediction\"]\n",
    " )\n",
    " .write\n",
    " .parquet(\"linreg_prediction.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions = spark.read.parquet(\"linreg_prediction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_predictions.select(\"prediction\").describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(estimator_pipeline, 'pipeline.joblib') \n",
    "\n",
    "reloaded = load(\"pipeline.joblib\")\n",
    "\n",
    "#Now we can predict directly!\n",
    "\n",
    "reloaded.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## save models DOESN'T WORK BECAUSE: 'NLTKWordPunctTokenizer' object has no attribute '_to_java'\n",
    "for i in data_array:\n",
    "    param_dict[i].save(f'{i}-pipeline') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 0-master-notebook-pipelines.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
