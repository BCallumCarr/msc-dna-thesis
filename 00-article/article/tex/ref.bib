@inproceedings{Titov2008,
abstract = {In this paper we present a novel framework for extracting the ratable aspects of objects from online user reviews. Extracting such aspects is an important challenge in automatically mining product opinions from the web and in generating opinion-based summaries of user reviews. Our models are based on extensions to standard topic modeling methods such as LDA and PLSA to induce multi-grain topics. We argue that multi-grain models are more appropriate for our task since standard models tend to produce topics that correspond to global properties of objects (e.g., the brand of a product type) rather than the aspects of an object that tend to be rated by a user. The models we present not only extract ratable aspects, but also cluster them into coherent topics, e.g., `waitress' and `bartender' are part of the same topic `staff' for restaurants. This differentiates it from much of the previous work which extracts aspects through term frequency analysis with minimal clustering. We evaluate the multi-grain models both qualitatively and quantitatively to show that they improve significantly upon standard topic models.},
archivePrefix = {arXiv},
arxivId = {arXiv:0801.1063v1},
author = {Titov, Ivan and McDonald, Ryan},
booktitle = {WWW},
doi = {10.1145/1367497.1367513},
eprint = {arXiv:0801.1063v1},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/titov-lda-online-reviews.pdf:pdf},
isbn = {9781605580852},
keywords = {Design,Experimentation},
pages = {111--120},
title = {{Modeling online reviews with multi-grain topic models}},
year = {2008}
}
@article{Chien2008,
abstract = {Due to the vast growth of data collections, the statistical document modeling has become increasingly important in language processing areas. Probabilistic latent semantic analysis (PLSA) is a popular approach whereby the semantics and statistics can be effectively captured for modeling. However, PLSA is highly sensitive to task domain, which is continuously changing in real-world documents. In this paper, a novel Bayesian PLSA framework is presented. We focus on exploiting the incremental learning algorithm for solving the updating problem of new domain articles. This algorithm is developed to improve document modeling by incrementally extracting up-to-date latent semantic information to match the changing domains at run time. By adequately representing the priors of PLSA parameters using Dirichlet densities, the posterior densities belong to the same distribution so that a reproducible prior/posterior mechanism is activated for incremental learning from constantly accumulated documents. An incremental PLSA algorithm is constructed to accomplish the parameter estimation as well as the hyperparameter updating. Compared to standard PLSA using maximum likelihood estimate, the proposed approach is capable of performing dynamic document indexing and modeling. We also present the maximum a posteriori PLSA for corrective training. Experiments on information retrieval and document categorization demonstrate the superiority of using Bayesian PLSA methods. {\textcopyright} 2006 IEEE.},
author = {Chien, Jen Tzung and Wu, Meng Sung},
doi = {10.1109/TASL.2007.909452},
file = {:Users/brad/Downloads/chien-adaptive-bayesian-latent-semantic-analysis.pdf:pdf},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Bayesian theory,Conjugate prior,Dirichlet distribution,Incremental learning,Natural language processing,Probabilistic latent semantic analysis,Statistical document modeling},
number = {1},
pages = {198--207},
title = {{Adaptive Bayesian latent semantic analysis}},
volume = {16},
year = {2008}
}
@article{Griffiths2004,
abstract = {A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. {\&} Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying "hot topics" by examining temporal dynamics and tagging abstracts to illustrate semantic content.},
author = {Griffiths, Thomas L. and Steyvers, Mark},
doi = {10.1073/pnas.0307752101},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/gibbs-sampling-scientific-topics-griffiths.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {SUPPL. 1},
pages = {5228--5235},
title = {{Finding scientific topics}},
volume = {101},
year = {2004}
}
@article{Deerwester1990,
author = {Deerwester, S. and Dumais, S. T. and Harshman, R.},
file = {:Users/brad/Downloads/deerwester-latent-semantic-analysis.pdf:pdf},
journal = {Journal of the American Society for Information Science},
number = {6},
pages = {391--407},
title = {{Indexing by Latent Semantic Analysis}},
volume = {41},
year = {1990}
}
@inproceedings{Asuncion2009,
abstract = {Latent Dirichlet analysis, or topic modeling, is a flexible latent variable framework for modeling high-dimensional sparse count data. Various learning algorithms have been developed in recent years, including collapsed Gibbs sampling, variational inference, and maximum a posteriori estimation, and this variety motivates the need for careful empirical comparisons. In this paper, we highlight the close connections between these approaches. We find that the main differences are attributable to the amount of smoothing applied to the counts. When the hyperparameters are optimized, the differences in performance among the algorithms diminish significantly. The ability of these algorithms to achieve solutions of comparable accuracy gives us the freedom to select computationally efficient approaches. Using the insights gained from this comparative study, we show how accurate topic models can be learned in several seconds on text corpora with thousands of documents.},
author = {Asuncion, Arthur and Welling, Max and Smyth, Padhraic and Teh, Yee Whye},
booktitle = {Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/smoothing-and-inference-topic-models-em.pdf:pdf},
pages = {27--34},
publisher = {AUAI Press},
title = {{On smoothing and inference for topic models}},
year = {2009}
}
@incollection{Hoerl1988,
address = {New York},
author = {Hoerl, A. and Kennard, R.},
booktitle = {Encyclopedia of Statistical Sciences},
edition = {8},
pages = {129--136},
publisher = {Wiley},
title = {{Ridge regression}},
year = {1988}
}
@article{Mikolov2013,
abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
archivePrefix = {arXiv},
arxivId = {1301.3781},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
eprint = {1301.3781},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/word2vec-mikolov-2013.pdf:pdf},
pages = {1--12},
title = {{Efficient Estimation of Word Representations in Vector Space}},
url = {http://arxiv.org/abs/1301.3781},
year = {2013}
}
@book{Salton1983,
author = {Salton, G. and McGill, M.J.},
publisher = {Mcgraw-Hill},
title = {{Introduction to modern information retrieval}},
year = {1983}
}
@inproceedings{Brody2010,
abstract = {With the increase in popularity of online review sites comes a corresponding need for tools capable of extracting the information most important to the user from the plain text data. Due to the diversity in products and services being reviewed, supervised methods are often not practical. We present an unsuper- vised system for extracting aspects and determining sentiment in review text. The method is simple and flexible with regard to domain and language, and takes into account the influence of aspect on sentiment polarity, an issue largely ignored in previous literature. We demonstrate its effectiveness on both component tasks, where it achieves similar results to more complex semi-supervised methods that are restricted by their reliance on manual annotation and extensive knowledge sources.},
author = {Brody, Samuel and Elhadad, Noemie},
booktitle = {HLT/NAACL},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/local-lda-sentence-models-brody:},
isbn = {1932432655},
pages = {804--812},
publisher = {Association for Computational Linguistics},
title = {{An unsupervised aspect-sentiment model for online reviews}},
year = {2010}
}
@article{Chen2009,
abstract = {We present a novel Bayesian topic model for learning discourse-level document structure. Our model leverages insights from discourse theory to constrain latent topic assignments in a way that reflects the underlying organization of document topics. We propose a global model in which both topic selection and ordering are biased to be similar across a collection of related documents. We show that this space of orderings can be elegantly represented using a distribution over permutations called the generalized Mallows model. Our structure-aware approach substantially outperforms alternative approaches for cross-document comparison and single-document segmentation.},
author = {Chen, Harr and Branavan, S. R.K. and Barzilay, Regina and Karger, David R.},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/gibbs-lda-chen-2009:},
isbn = {9781932432411},
journal = {NAACL HLT 2009 - Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
number = {June},
pages = {371--379},
title = {{Global models of document structure using latent permutations}},
year = {2009}
}
@article{Zou2005,
abstract = {... Additional Information. How to Cite. Zou , H . and Hastie , T . ( 2005 ), Regularization and variable selection via the elastic net . ... E-mail: hastie @stanford.edu. Publication History. ... In Section 3 , we show that this na{\{}{\"{i}}{\}}ve procedure tends to overshrink in regression problems. ... $\backslash$n},
author = {Zou, Hui and Hastie, Trevor},
doi = {10.1111/j.1467-9868.2005.00527.x},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/elasticnet-zou-hastie.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {grouping effect,lars algorithm,lasso,p,penalization},
number = {5},
pages = {768},
title = {{Erratum: Regularization and variable selection via the elastic net (Journal of the Royal Statistical Society. Series B: Statistical Methodology (2005) 67 (301-320))}},
volume = {67},
year = {2005}
}
@article{Hoffman2010,
abstract = {We develop an online variational Bayes (VB) algorithm for Latent Dirichlet Allocation (LDA). Online LDA is based on online stochastic optimization with a natural gradient step, which we show converges to a local optimum of the VB objective function. It can handily analyze massive document collections, including those arriving in a stream. We study the performance of online LDA in several ways, including by fitting a 100-topic topic model to 3.3M articles from Wikipedia in a single pass. We demonstrate that online LDA finds topic models as good or better than those found with batch VB, and in a fraction of the time.},
archivePrefix = {arXiv},
arxivId = {0710.4428v1},
author = {Hoffman, Matthew D and Blei, David M and Bach, Francis},
doi = {10.1.1.187.1883},
eprint = {0710.4428v1},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/online-learning-lda-hoffman.pdf:pdf},
isbn = {9781450300551},
issn = {08912017},
journal = {Nature},
pages = {1--9},
pmid = {4944952},
title = {{Online Learning for latent Dirichlet allocation (Supplementary Material)}},
url = {http://papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation.pdf},
year = {2010}
}
@book{Farmer2010,
author = {Farmer, R. and Glass, B.},
publisher = {O'Reilly Media, Inc},
title = {{Building web reputation systems}},
year = {2010}
}
@misc{StackExchange.com2019,
author = {StackExchange.com},
title = {{StackExchange Site Details}},
url = {https://stackexchange.com/sites},
year = {2019}
}
@misc{Alexa.com2019,
author = {Alexa.com},
title = {{The top 500 sites on the web}},
url = {https://www.alexa.com/topsites},
year = {2019}
}
@article{Chai2014,
abstract = {Abstract. Both the root mean square error (RMSE) and the mean absolute error (MAE) are regularly employed in model evaluation studies. Willmott and Matsuura (2005) have suggested that the RMSE is not a good indicator of average model performance and might be a misleading indicator of average error, and thus the MAE would be a better metric for that purpose. While some concerns over using RMSE raised by Willmott and Matsuura (2005) and Willmott et al. (2009) are valid, the proposed avoidance of RMSE in favor of MAE is not the solution. Citing the aforementioned papers, many researchers chose MAE over RMSE to present their model evaluation statistics when presenting or adding the RMSE measures could be more beneficial. In this technical note, we demonstrate that the RMSE is not ambiguous in its meaning, contrary to what was claimed by Willmott et al. (2009). The RMSE is more appropriate to represent model performance than the MAE when the error distribution is expected to be Gaussian. In addition, we show that the RMSE satisfies the triangle inequality requirement for a distance metric, whereas Willmott et al. (2009) indicated that the sums-of-squares-based statistics do not satisfy this rule. In the end, we discussed some circumstances where using the RMSE will be more beneficial. However, we do not contend that the RMSE is superior over the MAE. Instead, a combination of metrics, including but certainly not limited to RMSEs and MAEs, are often required to assess model performance.},
author = {Chai, T. and Draxler, R. R.},
doi = {10.5194/gmd-7-1247-2014},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/rmse-versus-mae-chai-2014.pdf:pdf},
issn = {19919603},
journal = {Geoscientific Model Development},
number = {3},
pages = {1247--1250},
title = {{Root mean square error (RMSE) or mean absolute error (MAE)? - Arguments against avoiding RMSE in the literature}},
volume = {7},
year = {2014}
}
@article{Ritter2010,
abstract = {The computation of selectional preferences, the admissible argument values for a relation, is a well-known NLP task with broad applicability. We present LDA-SP, which utilizes LinkLDA (Erosheva et al., 2004) to model selectional preferences. By simultaneously inferring latent topics and topic distributions over relations, LDA-SP combines the benefits of previous approaches: like traditional class-based approaches, it produces human-interpretable classes describing each relation's preferences, but it is competitive with non-class-based methods in predictive power. We compare LDA-SP to several state-of-the-art methods achieving an 85{\%} increase in recall at 0.9 precision over mutual information (Erk, 2007). We also evaluate LDA-SP's effectiveness at filtering improper applications of inference rules, where we show substantial improvement over Pantel et al.'s system (Pantel et al., 2007).},
author = {Ritter, Alan and Mausam and Etzioni, Oren},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/lda/selectional-preferences-ritter.pdf:pdf},
isbn = {9781617388088},
journal = {ACL},
number = {July},
pages = {424--434},
title = {{A latent dirichlet allocation method for selectional preferences}},
year = {2010}
}
@article{Eppler2004,
abstract = {Based on literature from the domains of organization science, marketing, accounting, and management information systems, this review article examines the theoretical basis of the information overload discourse and presents an overview of the main defini- tions, situations, causes, effects, and countermeasures. It analyzes the contributions from the last 30 years to consolidate the existing research in a conceptual framework and to identify future research directions.},
author = {Eppler, Martin J. and Mengis, Jeanne},
doi = {10.1080/01972240490507974},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/lda/eppler-information-overload.pdf:pdf},
issn = {01972243},
journal = {Information Society},
keywords = {Information explosion,Information management strategies,Information overload,Information processing,Information skills,Information technology},
number = {5},
pages = {325--344},
title = {{The concept of information overload: A review of literature from organization science, accounting, marketing, MIS, and related disciplines}},
volume = {20},
year = {2004}
}
@article{Daume2006,
abstract = {We present BayeSum (for ``Bayesian summarization''), a model for sentence extraction in query-focused summarization. BayeSum leverages the common case in which multiple documents are relevant to a single query. Using these documents as reinforcement for query terms, BayeSum is not afflicted by the paucity of information in short queries. We show that approximate inference in BayeSum is possible on large data sets and results in a state-of-the-art summarization system. Furthermore, we show how BayeSum can be understood as a justified query expansion technique in the language modeling for IR framework.},
archivePrefix = {arXiv},
arxivId = {arXiv:0907.1814v1},
author = {Daum{\'{e}}, Hal and Marcu, Daniel},
eprint = {arXiv:0907.1814v1},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/lda/bayesian-query-focused-summarization-daume.pdf:pdf},
isbn = {1932432655},
journal = {ACL},
pages = {305--312},
title = {{Bayesian query-focused summarization}},
volume = {1},
year = {2006}
}
@inproceedings{Kozareva2011,
abstract = {Resolving ambiguity associated with names found on the Web, Wikipedia or medical texts is a very challenging task, which has been of great interest to the research community. We propose a novel approach to disambiguat-ing names using Latent Dirichlet Allocation, where the learned topics represent the under-lying senses of the ambiguous name. We con-duct a detailed evaluation on multiple data sets containing ambiguous person, location and or-ganization names and for multiple languages such as English, Spanish, Romanian and Bul-garian. We conduct comparative studies with existing approaches and show a substantial improvement of 15 to 35{\%} in task accuracy.},
author = {Kozareva, Zornitsa and Ravi, Sujith},
booktitle = {Proc. 1st Workshop on Unsupervised Learning in NLP},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/lda/name-ambiguity-resolution-kozareva.pdf:pdf},
pages = {105--112},
title = {{Unsupervised name ambiguity resolution using a generative model}},
url = {http://dl.acm.org/citation.cfm?id=2140471},
year = {2011}
}
@inproceedings{Haghighi2010,
author = {Haghighi, Aria and Klein, Dan},
booktitle = {HLT/NAACL},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/lda/coreference-resolution-haghighi.pdf:pdf},
pages = {385--393},
title = {{Coreference Resolution in a Modular, Entity-Centered Model}},
year = {2010}
}
@inproceedings{Reisinger2009,
abstract = {This paper presents a set of Bayesian methods for automatically extending the WORDNET ontology with new concepts and annotating existing concepts with generic property fields, or attributes. We base our approach on Latent Dirichlet Al- location and evaluate along two dimen- sions: (1) the precision of the ranked lists of attributes, and (2) the quality of the attribute assignments to WORDNET concepts. In all cases we find that the principled LDA-based approaches outper- form previously proposed heuristic meth- ods, greatly improving the specificity of attributes at each concept.},
author = {Reisinger, Joseph and Paşca, Marius},
booktitle = {ACL/IJCNLP},
doi = {10.3115/1690219.1690233},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/lda/concept-attribute-attachment-reisinger.pdf:pdf},
pages = {620--628},
title = {{Latent variable models of concept-attribute attachment}},
year = {2009}
}
@article{Porter1980,
author = {Porter, M. F.},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/porter-1980.txt:txt},
journal = {Program},
number = {3},
pages = {130--137},
title = {{An algorithm for suffix stripping}},
volume = {14},
year = {1980}
}
@misc{Gervais2015,
abstract = {ABSTRACTWith the advances in interpersonal communication of the ``Web 2.0'' era, questions about the importance of civility are perhaps more important than ever. Mass digital interaction between strangers has become an everyday occurrence, bound by few behavioral norms. I argue that the widespread presence of incivility in online political communication limits the deliberative potential of online interactions. To test this hypothesis, I manipulate exposure to uncivil political discourse in an online discussion forum. I find that exposure to disagreeable uncivil political talk induces feelings of anger and aversion, which in turn reduces satisfaction with the message board discourse. On the other hand, exposure to like-minded incivility increases the use of uncivil behavior in political comments by message board posters. Notably, these effects mainly occur when histrionic, emotional incivility is present. I discuss why like-minded and disagreeable incivility have different effects, and reflect on what the presence of incivility means for online political discourse.},
author = {Gervais, Bryan T.},
booktitle = {Journal of Information Technology {\&} Politics},
doi = {10.1080/19331681.2014.997416},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/incivility-online/Incivility Online - Affective and Behavioral Reactions to Uncivil Political Posts in a Web based Experiment.pdf:pdf},
issn = {1933169X},
keywords = {Affective intelligence,incivility,online discourse,political deliberation,political discourse},
number = {2},
pages = {167--185},
title = {{Incivility Online: Affective and Behavioral Reactions to Uncivil Political Posts in a Web-based Experiment}},
volume = {12},
year = {2015}
}
@inproceedings{Berry2017,
abstract = {Studies of online social influence have demonstrated that friends have important effects on many types of behavior in a wide variety of settings. However, we know much less about how influence works among relative strangers in digital public squares, despite important conversations happening in such spaces. We present the results of a study on large public Facebook pages where we randomly used two different methods--most recent and social feedback--to order comments on posts. We find that the social feedback condition results in higher quality viewed comments and response comments. After measuring the average quality of comments written by users before the study, we find that social feedback has a positive effect on response quality for both low and high quality commenters. We draw on a theoretical framework of social norms to explain this empirical result. In order to examine the influence mechanism further, we measure the similarity between comments viewed and written during the study, finding that similarity increases for the highest quality contributors under the social feedback condition. This suggests that, in addition to norms, some individuals may respond with increased relevance to high-quality comments.},
archivePrefix = {arXiv},
arxivId = {1702.06677},
author = {Berry, George and Taylor, Sean J.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
eprint = {1702.06677},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/incivility-online/facebook-incivility-berry.pdf:pdf},
isbn = {9781450349130},
keywords = {comment ranking,online discussions,social,social influence},
pages = {1371 -- 1380},
publisher = {International World Wide Web Conferences Steering Committee},
title = {{Discussion quality diffuses in the digital public square}},
url = {http://arxiv.org/abs/1702.06677},
year = {2017}
}
@inproceedings{Sung2013,
abstract = {Community-based question answering(CQA) services such asYahoo! Answers have been widely used by Internet users to get the answers for their inquiries. The CQA services totally rely on the contributions by the users. However, it is known that newcomers are prone to lose their interests and leave the communities. Thus, finding expert users in an early phase when they are still active is essential to improve the chances of motivating them to contribute to the communities further. In this paper, we propose a novel approach to discovering “potentially” contributive users from recently-joined users in CQAservices. The likelihood of becoming a contributive user is defined by the user's expertise as well as availability, which we call the answer affordance. The main technical difficulty lies in the fact that such recently-joined users do not have abundant information accumulated for many years. We uti- lize a user's productive vocabulary to mitigate the lack of available information since the vocabulary is the most fun- damental element that reveals his/her knowledge. Extensive experiments were conducted with a huge data set of Naver Knowledge-In (KiN), which is the dominating CQA service in Korea.We demonstrate that the top rankers selected by the answer affordance outperformed those by KiN in terms of the amount of answering activity. Introduction},
author = {Sung, Juyup and Lee, Jae-gil and Lee, Uichin},
booktitle = {ICWSM},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Sung, Lee, Lee - 2013 - Booming Up the Long Tails Discovering Potentially Contributive Users in Community-Based Question Answering Servi.pdf:pdf},
keywords = {community based question answering,heavy users,light users,social services},
pages = {602--610},
title = {{Booming Up the Long Tails: Discovering Potentially Contributive Users in Community-Based Question Answering Services}},
year = {2013}
}
@inproceedings{Qu2009,
abstract = {User-InteractiveQuestion Answering (QA) communities such as Yahoo! Answers are growing in popularity. However, as these QA sites always have thousands of new questions posted daily, it is difficult for users to find the questions that are of interest to them. Consequently, this may delay the an- swering of the new questions. This gives rise to question rec- ommendation techniques that help users locate interesting questions. In this paper, we adopt the Probabilistic Latent Semantic Analysis (PLSA) model for question recommenda- tion and propose a novel metric to evaluate the performance of our approach. The experimental results show our recom- mendation approach is effective.},
author = {Qu, Mingcheng and Qiu, Guang and He, Xiaofei and Zhang, Cheng and Wu, Hao and Bu, Jiajun and Chen, Chun},
booktitle = {WWW},
doi = {10.1145/1526709.1526942},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Qu et al. - 2009 - Probabilistic question recommendation for question answering communities.pdf:pdf},
isbn = {9781605584874},
keywords = {plsa,question answering,question recommendation},
pages = {1229--1230},
title = {{Probabilistic question recommendation for question answering communities}},
year = {2009}
}
@inproceedings{Li2011,
abstract = {This paper investigates a ground-breaking incorporation of question category to Question Routing (QR) in Commu- nity Question Answering (CQA) services. The incorpora- tion of question category was designed to estimate answerer expertise for routing questions to potential answerers. Two category-sensitive Language Models (LMs) were developed with large-scale real world data sets being experimented. Results demonstrated that higher accuracies of routing ques- tions with lower computational costs were achieved, relative to traditional Query Likelihood LM (QLLM), state-of-the- art Cluster-Based LM (CBLM) and the mixture of Latent Dirichlet Allocation and QLLM (LDALM).},
author = {Li, Baichuan and King, Irwin and Lyu, Michael R.},
booktitle = {CIKM},
doi = {10.1145/2063576.2063885},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Li, King, Lyu - 2011 - Question routing in community question answering.pdf:pdf},
isbn = {9781450307178},
keywords = {category,category-sensitive language model,community question answering,question,question routing},
pages = {2041--2044},
title = {{Question routing in community question answering}},
year = {2011}
}
@inproceedings{Li2010,
abstract = {Community Question Answering (CQA) service provides a platform for increasing number of users to ask and answer for their own needs but unanswered questions still exist within a fixed period. To address this, the paper aims to route questions to the right answerers who have a top rank in accordance of their previous answering performance. In order to rank the answerers, we propose a framework called Question Routing (QR) which consists of four phases: (1) performance profiling, (2) expertise estimation, (3) availability estimation, and (4) answerer ranking. Applying the framework, we conduct experiments with Yahoo! Answers dataset and the results demonstrate that on average each of 1,713 testing questions obtains at least one answer if it is routed to the top 20 ranked answerers.},
author = {Li, Baichuan and King, Irwin},
booktitle = {CIKM},
doi = {10.1145/1871437.1871678},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Li, King - 2010 - Routing questions to appropriate answerers in community question answering services.pdf:pdf},
isbn = {9781450300995},
keywords = {community question answering,question routing},
pages = {1585--1588},
title = {{Routing questions to appropriate answerers in community question answering services}},
year = {2010}
}
@inproceedings{Zhou2012,
author = {Zhou, Tom Chao and Lyu, Michael R and King, Irwin},
booktitle = {WWW Companion},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Zhou, Lyu, King - 2012 - A classification-based approach to question routing in community question answering.pdf:pdf},
isbn = {9781450312301},
pages = {783--790},
title = {{A classification-based approach to question routing in community question answering}},
year = {2012}
}
@inproceedings{Szpektor2013,
author = {Szpektor, Idan and Maarek, Yoelle and Pelleg, Dan},
booktitle = {WWW},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Szpektor, Maarek, Pelleg - 2013 - When relevance is not enough promoting diversity and freshness in personalized question recommendation.pdf:pdf},
isbn = {9781450320351},
pages = {1249--1260},
title = {{When relevance is not enough: promoting diversity and freshness in personalized question recommendation}},
year = {2013}
}
@inproceedings{Wu2008,
abstract = {With the fast development of web 2.0, user-centric publishing and knowledge management platforms, such as Wiki, Blogs, and Q {\&} A systems attract a large number of users. Given the availability of the huge amount of meaningful user generated content, incremental model based recommendation techniques can be employed to improve users' experience using automatic recommendations. In this paper, we propose an incremental recommendation algorithm based on Probabilistic Latent Semantic Analysis (PLSA). The proposed algorithm can consider not only the users' long-term and short-term interests, but also users' negative and positive feedback. We compare the proposed method with several baseline methods using a real-world Question {\&} Answer website called Wenda. Experiments demonstrate both the effectiveness and the efficiency of the proposed methods.},
author = {Wu, Hu and Wang, Yongji and Cheng, Xiang},
booktitle = {RecSys},
doi = {10.1145/1454008.1454026},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Wu, Wang, Cheng - 2008 - Incremental probabilistic latent semantic analysis for automatic question recommendation.pdf:pdf},
isbn = {9781605580937},
keywords = {incremental learning,plsa,recommendation system},
pages = {99--106},
title = {{Incremental probabilistic latent semantic analysis for automatic question recommendation}},
year = {2008}
}
@inproceedings{Shah2010,
abstract = {Question answering (QA) helps one go beyond traditional keywords-based querying and retrieve information in more precise form than given by a document or a list of documents. Several community-based QA (CQA) services have emerged allowing information seekers pose their information need as questions and receive answers from their fellow users. A question may receive multiple answers from multiple users and the asker or the community can choose the best answer. While the asker can thus indicate if he was satisfied with the information he received, there is no clear way of evaluating the quality of that information. We present a study to evaluate and predict the quality of an answer in a CQA setting. We chose Yahoo! Answers as such CQA service and selected a small set of questions, each with at least five answers. We asked Amazon Mechanical Turk workers to rate the quality of each answer for a given question based on 13 different criteria. Each answer was rated by five different workers. We then matched their assessments with the actual asker's rating of a given answer. We show that the quality criteria we used faithfully match with asker's perception of a quality answer. We furthered our investigation by extracting various features from questions, answers, and the users who posted them, and training a number of classifiers to select the best answer using those features. We demonstrate a high predictability of our trained models along with the relative merits of each of the features for such prediction. These models support our argument that in case of CQA, contextual information such as a user's profile, can be critical in evaluating and predicting content quality.},
author = {Shah, Chirag and Pomerantz, Jefferey},
booktitle = {SIGIR},
doi = {10.1145/1835449.1835518},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Shah, Pomerantz - 2010 - Evaluating and predicting answer quality in community QA.pdf:pdf},
isbn = {9781605588964},
keywords = {-based querying and retrieve,a list of documents,allowing information seekers pose,by a document or,cqa,information in more,precise form than given,services have emerged,several community-based qa,their information need as},
pages = {411--418},
title = {{Evaluating and predicting answer quality in community QA}},
year = {2010}
}
@inproceedings{Jeon2006,
abstract = {New types of document collections are being developed by various web services. The service providers keep track of non-textual features such as click counts. In this paper, we present a framework to use non-textual features to predict the quality of documents. We also show our quality measure can be successfully incorporated into the language modeling-based retrieval model. We test our approach on a collection of question and answer pairs gathered from a community based question answering service where people ask and answer questions. Experimental results using our quality measure show a significant improvement over our baseline.},
author = {Jeon, Jiwoon and Croft, W. Bruce and Lee, Joon Ho and Park, Soyeon},
booktitle = {SIGIR},
doi = {10.1145/1148170.1148212},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Jeon et al. - 2006 - A framework to predict the quality of answers with non-textual features.pdf:pdf},
isbn = {1595933697},
keywords = {document qual-,information retrieval,ity,language models,maximum entropy},
pages = {228--235},
title = {{A framework to predict the quality of answers with non-textual features}},
year = {2006}
}
@inproceedings{Liu2008,
abstract = {Question answering communities such as Naver and Yahoo! An- swers have emerged as popular, and often effective, means of infor- mation seeking on the web. By posting questions for other partic- ipants to answer, information seekers can obtain specific answers to their questions. Users of popular portals such as Yahoo! An- swers already have submitted millions of questions and received hundreds of millions of answers from other participants. However, it may also take hours –and sometime days– until a satisfactory an- swer is posted. In this paper we introduce the problemof predicting information seeker satisfaction in collaborative question answering communities, where we attempt to predict whether a question au- thor will be satisfied with the answers submitted by the community participants. We present a general prediction model, and de- velop a variety of content, structure, and community-focused fea- tures for this task. Our experimental results, obtained from a large- scale evaluation over thousands of real questions and user ratings, demonstrate the feasibility of modeling and predicting asker satis- faction. We complement our results with a thorough investigation of the interactions and information seeking patterns in question an- swering communities that correlate with information seeker satis- faction. Our models and predictions could be useful for a variety of applications such as user intent inference, answer ranking, interface design, and query suggestion and routing.},
author = {Liu, Yandong and Bian, Jiang and Agichtein, Eugene},
booktitle = {SIGIR},
doi = {10.1145/1390334.1390417},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Liu, Bian, Agichtein - 2008 - Predicting information seeker satisfaction in community question answering.pdf:pdf},
isbn = {9781605581644},
keywords = {community question answering,information seeker satisfaction},
pages = {483--490},
title = {{Predicting information seeker satisfaction in community question answering}},
url = {http://portal.acm.org/citation.cfm?doid=1390334.1390417},
year = {2008}
}
@inproceedings{Riahi2012,
abstract = {Community Question Answering (CQA) websites provide a rapidly growing source of information in many areas. This rapid growth, while offering new opportunities, puts forward new challenges. In most CQA implementations there is little effort in directing new questions to the right group of experts. This means that experts are not provided with questions matching their expertise, and therefore new matching questions may be missed and not receive a proper answer. We focus on finding experts for a newly posted question. We investigate the suitability of two statistical topic models for solving this issue and compare these methods against more traditional Information Retrieval approaches. We show that for a dataset constructed from the Stackoverflow website, these topic models outperform other methods in retrieving a candidate set of best experts for a question. We also show that the Segmented Topic Model gives consistently better performance compared to the Latent Dirichlet Allocation Model.},
author = {Riahi, Fatemeh and Zolaktaf, Zainab and Shafiei, Mahdi and Milios, Evangelos},
booktitle = {WWW Companion},
doi = {10.1145/2187980.2188202},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Riahi et al. - 2012 - Finding expert users in community question answering.pdf:pdf},
isbn = {9781450312301},
keywords = {community question answering,expert recommendation,language,model,tf-idf,topic modeling},
pages = {791--798},
title = {{Finding expert users in community question answering}},
year = {2012}
}
@inproceedings{Tian2013,
abstract = {Community-based question-answering (CQA) services contribute to solving many difficult questions we have. For each question in such services, one best answer can be designated, among all answers, often by the asker. However, many questions on typical CQA sites are left without a best answer even if when good candidates are available. In this paper, we attempt to address the prob-lem of predicting if an answer may be selected as the best answer, based on learning from labeled data. The key tasks include designing features measuring impor-tant aspects of an answer and identifying the most im-portance features. Experiments with a Stack Overflow dataset show that the contextual information among the answers should be the most important factor to consider.},
author = {Tian, Qiongjie and Zhang, Peng and Li, Baoxin},
booktitle = {ICWSM},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Tian, Zhang, Li - 2013 - Towards Predicting the Best Answers in Community-Based Question-Answering Services.pdf:pdf},
pages = {725--728},
title = {{Towards Predicting the Best Answers in Community-Based Question-Answering Services}},
year = {2013}
}
@inproceedings{Agichtein2008,
abstract = {The quality of user-generated content varies drastically from excellent to abuse and spam. As the availability of such content increases, the task of identifying high-quality content in sites based on user contributions—social media sites— becomes increasingly important. Social media in general exhibit a rich variety of information sources: in addition to the content itself, there is a wide array of non-content information available, such as links between items and explicit quality ratings from members of the community. In this paper we investigate methods for exploiting such community feedback to automatically identify high quality content. As a test case, we focus on Yahoo! Answers, a large community question/answering portal that is particularly rich in the amount and types of content and social interactions available in it. We introduce a general classification framework for combining the evidence from different sources of information, that can be tuned automatically for a given social media type and quality definition. In particular, for the community question/answering domain, we show that our system is able to separate high-quality items from the rest with an accuracy close to that of humans.},
author = {Agichtein, E. and Castillo, C. and Donato, D. and Gionis, A. and Mishne, G.},
booktitle = {Proceedings of the 2008 International Conference on Web Search and Data Mining},
doi = {10.1145/1341531.1341557},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Agichtein et al. - 2008 - Finding high-quality content in social media.pdf:pdf},
isbn = {978-1-59593-927-2},
issn = {15435008},
keywords = {Community Question Answering,Social media,User I},
pages = {183--194},
pmid = {11},
title = {{Finding high-quality content in social media}},
url = {http://dl.acm.org/citation.cfm?id=1341557{\&}CFID=258789117{\&}CFTOKEN=24893236},
year = {2008}
}
@inproceedings{Bian2009,
abstract = {Community Question Answering (CQA) has emerged as a popular forum for users to pose questions for other users to answer. Over the last few years, CQA portals such as Naver and Yahoo! Answers have exploded in popularity, and now provide a viable alternative to general purpose Web search. At the same time, the answers to past questions submit- ted in CQA sites comprise a valuable knowledge repository which could be a gold mine for information retrieval and automatic question answering. Unfortunately, the quality of the submitted questions and answers varies widely - in- creasingly so that a large fraction of the content is not usable for answering queries. Previous approaches for retrieving relevant and high quality content have been proposed, but they require large amounts of manually labeled data – which limits the applicability of the supervised approaches to new sites and domains. In this paper we address this problem by developing a semi-supervised coupled mutual reinforce- ment framework for simultaneously calculating content qual- ity and user reputation, that requires relatively few labeled examples to initialize the training process. Results of a large scale evaluation demonstrate that our methods are more ef- fective than previous approaches for finding high-quality an- swers, questions, and users. More importantly, our quality estimation significantly improves the accuracy of search over CQA archives over the state-of-the-art methods.},
author = {Bian, Jiang and Liu, Yandong and Zhou, Ding and Agichtein, Eugene and Zha, Hongyuan},
booktitle = {Proceedings of the 18th international conference on World wide web},
doi = {10.1145/1526709.1526717},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Bian et al. - 2009 - Learning to recognize reliable users and content in social media with coupled mutual reinforcement.pdf:pdf},
isbn = {9781605584874},
keywords = {authority and expertise,community question answering,copyright is held by,in online communities,the international world wide,web conference com-},
pages = {51--60},
title = {{Learning to recognize reliable users and content in social media with coupled mutual reinforcement}},
year = {2009}
}
@inproceedings{Li2012,
abstract = {Users tend to ask and answer questions in community question answering (CQA) services to seek information and share knowledge. A corollary is that myriad of questions and answers appear in CQA service. Accordingly, volumes of studies have been taken to explore the answer quality so as to provide a preliminary screening for better answers. However, to our knowledge, less attention has so far been paid to question quality in CQA. Knowing question quality provides us with finding and recommending good questions together with identifying bad ones which hinder the CQA service. In this paper, we are conducting two studies to investigate the question quality issue. The first study analyzes the factors of question quality and finds that the interaction between askers and topics results in the differences of question quality. Based on this finding, in the second study we propose a Mutual Reinforcement-based Label Propagation (MRLP) algorithm to predict question quality. We experiment with Yahoo!{\~{}}Answers data and the results demonstrate the effectiveness of our algorithm in distinguishing high-quality questions from low-quality ones.},
author = {Li, Baichuan and Jin, Tan and Lyu, Michael R. and King, Irwin and Mak, Barley},
booktitle = {WWW Companion},
doi = {10.1145/2187980.2188200},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2012 - Analyzing and predicting question quality in community question answering services.pdf:pdf},
isbn = {9781450312301},
keywords = {analy-,community question answering,question quality},
pages = {775--782},
title = {{Analyzing and predicting question quality in community question answering services}},
year = {2012}
}
@inproceedings{Anderson2012,
abstract = {Question answering (Q{\&}A) websites are now large repositories of valuable knowledge. While most Q{\&}A sites were initially aimed at providing useful answers to the question asker, there has been a marked shift towards question answering as a community-driven knowledge creation process whose end product can be of enduring value to a broad audience. As part of this shift, specific expertise and deep knowledge of the subject at hand have become increasingly important, and many Q{\&}A sites employ voting and reputation mechanisms as centerpieces of their design to help users identify the trustworthiness and accuracy of the content. To better understand this shift in focus from one-off answers to a group knowledge-creation process, we consider a question together with its entire set of corresponding answers as our fundamental unit of analysis, in contrast with the focus on individual questionanswer pairs that characterized previous work. Our investigation considers the dynamics of the community activity that shapes the set of answers, both how answers and voters arrive over time and how this influences the eventual outcome. For example, we observe significant assortativity in the reputations of co-answerers, relationships between reputation and answer speed, and that the probability of an answer being chosen as the best one strongly depends on temporal characteristics of answer arrivals. We then show that our understanding of such properties is naturally applicable to predicting several important quantities, including the long-term value of the question and its answers, as well as whether a question requires a better answer. Finally, we discuss the implications of these results for the design of Q{\&}A sites.},
author = {Anderson, A. and Huttenlocher, D. and Kleinberg, J. and Leskovec, J.},
booktitle = {KDD},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Anderson et al. - 2012 - Discovering value from community activity on focused question answering sites a case study of stack overflow.pdf:pdf},
isbn = {9781450314626},
keywords = {question-answering,reputation,value prediction},
pages = {850--858},
publisher = {ACM},
title = {{Discovering value from community activity on focused question answering sites: a case study of stack overflow}},
url = {http://dl.acm.org/citation.cfm?id=2339665},
year = {2012}
}
@article{Liu2017,
abstract = {Community question answering services (CQAS) (e.g., Yahoo! Answers)
provides a platform where people post questions and answer questions
posed by others. Previous works analyzed the answer quality (AQ) based
on answer-related features, but neglect the question-related features on
AQ. Previous work analyzed how asker-and question-related features
affect the question quality (QQ) regarding the amount of attention from
users, the number of answers and the question solving latency, but
neglect the correlation between QQ and AQ (measured by the rating of the
best answer), which is critical to quality of service (QoS). We handle
this problem from two aspects. First, we additionally use QQ in
measuring AQ, and analyze the correlation between a comprehensive list
of features (including answer-related features) and QQ. Second, we
propose the first method that estimates the probability for a given
question to obtain high AQ. Our analysis on the Yahoo! Answers trace
confirmed that the list of our identified features exert influence on
AQ, which determines QQ. For the correlation analysis, the previous
classification algorithms cannot consider the mutual interactions
between multiple ({\textgreater}2) classes of features. We then propose a novel
Coupled Semi-Supervised Mutual Reinforcement-based Label Propagation
(CSMRLP) algorithm for this purpose. Our extensive experiments show that
CSMRLP outperforms the Mutual Reinforcement-based Label Propagation
(MRLP) and five other traditional classification algorithms in the
accuracy of AQ classification, and the effectiveness of our proposed
method in AQ prediction. Finally, we provide suggestions on how to
create a question that will receive high AQ, which can be exploited to
improve the QoS of CQAS.},
author = {Liu, Jinwei and Shen, Haiying and Yu, Lei},
doi = {10.1109/TSC.2015.2446991},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Liu, Shen, Yu - 2017 - Question quality analysis and prediction in community question answering services with coupled mutual reinforceme.pdf:pdf},
issn = {19391374},
journal = {IEEE Transactions on Services Computing},
keywords = {Answer quality,Classification,Community question answering,Prediction,Question quality},
number = {2},
pages = {286--301},
publisher = {IEEE},
title = {{Question quality analysis and prediction in community question answering services with coupled mutual reinforcement}},
volume = {10},
year = {2017}
}
@article{Baltadzhieva2015,
abstract = {Community Question Answering websites (CQA) offer a new opportunity for users to provide, search and share knowl-edge. Although the idea of receiving a direct, targeted re-sponse to a question sounds very attractive, the quality of the question itself can have an important effect on the like-lihood of getting useful answers. High quality questions im-prove the CQA experience and therefore it is essential for CQA forums to better understand what characterizes ques-tions that are more appealing for the forum community. In this survey, we review existing research on question quality in CQA websites. We discuss the possible measures of ques-tion quality and the question features that have been shown to influence question quality.},
author = {Baltadzhieva, Antoaneta and Chrupa{\l}a, Grzegorz},
doi = {10.1145/2830544.2830547},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Baltadzhieva, Chrupa{\l}a - 2015 - Question Quality in Community Question Answering Forums.pdf:pdf},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
keywords = {community question answering,question,question quality},
number = {1},
pages = {8--13},
title = {{Question Quality in Community Question Answering Forums}},
volume = {17},
year = {2015}
}
@article{Brinton2014,
abstract = {We study user behavior in the courses offered by a major Massive Online Open Course (MOOC) provider during the summer of 2013. Since social learning is a key element of scalable education in MOOCs and is done via online discussion forums, our main focus is in understanding forum activities. Two salient features of MOOC forum activities drive our research: 1. High decline rate: for all courses studied, the volume of discussions in the forum declines continuously throughout the duration of the course. 2. High-volume, noisy discussions: at least 30{\%} of the courses produce new discussion threads at rates that are infeasible for students or teaching staff to read through. Furthermore, a substantial portion of the discussions are not directly course-related. We investigate factors that correlate with the decline of activity in the online discussion forums and find effective strategies to classify threads and rank their relevance. Specifically, we use linear regression models to analyze the time series of the count data for the forum activities and make a number of observations, e.g., the teaching staff's active participation in the discussion increases the discussion volume but does not slow down the decline rate. We then propose a unified generative model for the discussion threads, which allows us both to choose efficient thread classifiers and design an effective algorithm for ranking thread relevance. Our ranking algorithm is further compared against two baseline algorithms, using human evaluation from Amazon Mechanical Turk. The authors on this paper are listed in alphabetical order. For media and press coverage, please refer to us collectively, as "researchers from the EDGE Lab at Princeton University, together with collaborators at Boston University and Microsoft Corporation."},
archivePrefix = {arXiv},
arxivId = {1312.2159},
author = {Brinton, Christopher G. and Chiang, Mung and Jain, Shaili and Lam, Henry and Liu, Zhenming and Wong, Felix Ming Fai},
doi = {10.1109/TLT.2014.2337900},
eprint = {1312.2159},
file = {:Users/brad/Dropbox/lse-thesis-brad/articles/vojnovic-milan/Learning about social learning in MOOCs From Statistical Analysis to Generative Model.pdf:pdf},
isbn = {9781450326698},
issn = {19391382},
journal = {IEEE Transactions on Learning Technologies},
keywords = {MOOC,concept learning,data mining,regression,social learning networks},
number = {4},
pages = {346--359},
pmid = {24528267},
publisher = {IEEE},
title = {{Learning about social learning in MOOCs: From statistical analysis to generative model}},
volume = {7},
year = {2014}
}
@misc{Rasmussen2015,
author = {Rasmussen, Carl Edward},
file = {:Users/brad/Downloads/rasmussen-lda.pdf:pdf},
pages = {1--17},
title = {{Latent Dirichlet Allocation for Topic Modelling}},
year = {2015}
}
@article{Blei2010,
abstract = {With the effectiveness of therapeutic agents ever decreasing and the increased incidence of multi-drug resistant pathogens, there is a clear need for administration of more potent, potentially more toxic, drugs. Alternatively, biopharmaceuticals may hold potential but require specialised protection from premature in vivo degradation. Thus, a paralleled need for specialised drug delivery systems has arisen. Although cell-mediated drug delivery is not a completely novel concept, the few applications described to date are not yet ready for in vivo application, for various reasons such as drug-induced carrier cell death, limited control over the site and timing of drug release and/or drug degradation by the host immune system. Here, we present our hypothesis for a new drug delivery system, which aims to negate these limitations. We propose transport of nanoparticle-encapsulated drugs inside autologous macrophages polarised to M1 phenotype for high mobility and treated to induce transient phagosome maturation arrest. In addition, we propose a significant shift of existing paradigms in the study of host-microbe interactions, in order to study microbial host immune evasion and dissemination patterns for their therapeutic utilisation in the context of drug delivery. We describe a system in which microbial strategies may be adopted to facilitate absolute control over drug delivery, and without sacrificing the host carrier cells. We provide a comprehensive summary of the lessons we can learn from microbes in the context of drug delivery and discuss their feasibility for in vivo therapeutic application. We then describe our proposed “synthetic microbe drug delivery system” in detail. In our opinion, this multidisciplinary approach may hold the solution to effective, controlled drug delivery.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Blei, D. and Carin, L. and Dunson, D.},
doi = {10.1038/jid.2014.371},
eprint = {NIHMS150003},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/blei-2010.pdf:pdf},
isbn = {6176321972},
issn = {15378276},
journal = {IEEE signal processing magazine},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
number = {6},
pages = {55--65},
pmid = {1000000221},
title = {{Probabilistic Topic Models: A focus on graphical model design and applications to document and image analysis}},
volume = {27},
year = {2010}
}
@article{Willmott2009,
abstract = {Commonly used sums-of-squares-based error or deviation statistics-like the standard deviation, the standard error, the coefficient of variation, and the root-mean-square error-often are misleading indicators of average error or variability. Sums-of-squares-based statistics are functions of at least two dissimilar patterns that occur within data. Both the mean of a set of error or deviation magnitudes (the average of their absolute values) and their variability influence the value of a sum-of-squares-based error measure, which confounds clear assessment of its meaning. Interpretation problems arise, according to Paul Mielke, because sums-of-squares-based statistics do not satisfy the triangle inequality. We illustrate the difficulties in interpreting and comparing these statistics using hypothetical data, and recommend the use of alternate statistics that are based on sums of error or deviation magnitudes. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Willmott, Cort J. and Matsuura, Kenji and Robeson, Scott M.},
doi = {10.1016/j.atmosenv.2008.10.005},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/ambiguities-rmse-wilmott.pdf:pdf},
issn = {13522310},
journal = {Atmospheric Environment},
keywords = {Error statistics,Mean-absolute deviation,Standard deviation,Standard error},
pages = {749--752},
publisher = {Elsevier Ltd},
title = {{Ambiguities inherent in sums-of-squares-based error statistics}},
url = {http://dx.doi.org/10.1016/j.atmosenv.2008.10.005},
volume = {43},
year = {2009}
}
@article{Willmott2005,
abstract = {The relative abilities of 2, dimensioned statistics—the root-mean-square error (RMSE) and the mean absolute error (MAE)—to describe average model-performance error are examined. The RMSE is of special interest because it is widely reported in the climatic and environmental liter- ature; nevertheless, it is an inappropriate and misinterpreted measure of average error. RMSE is inappropriate because it is a function of 3 characteristics of a set of errors, rather than of one (the average error). RMSE varies with the variability within the distribution of error magnitudes and with the square root of the number of errors (n1/2), as well as with the average-error magnitude (MAE). Our findings indicate that MAE is a more natural measure of average error, and (unlike RMSE) is unambiguous. Dimensioned evaluations and inter-comparisons of average model-performance error, therefore, should be based on MAE.},
author = {Willmott, Cort and Matsuura, Kenji},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/advantages-mae-wilmott.pdf:pdf},
journal = {Climate Research},
keywords = {Mean absolute error,Model-performance measures,Root-mean-square error},
pages = {79--82},
title = {{Advantages of the Mean Abso- lute Error (MAE) over the Root Mean Square Error (RMSE) in assessing average model performance}},
url = {www.int-res.com},
volume = {30},
year = {2005}
}
@inproceedings{Shah2018,
abstract = {A matching in a two-sided market often incurs an externality: a matched resource may become unavailable to the other side of the market, at least for a while. This is especially an issue in online platforms involving human experts as the expert resources are often scarce. The efficient utilization of experts in these platforms is made challenging by the fact that the information available about the parties involved is usually limited. To address this challenge, we develop a model of a task-expert matching system where a task is matched to an expert using not only the prior information about the task but also the feedback obtained from the past matches. In our model the tasks arrive online while the experts are fixed and constrained by a finite service capacity. For this model, we characterize the maximum task resolution throughput a platform can achieve. We show that the natural greedy approaches where each expert is assigned a task most suitable to her skill is suboptimal, as it does not internalize the above externality. We develop a throughput optimal backpressure algorithm which does so by accounting for the `congestion' among different task types. Finally, we validate our model and confirm our theoretical findings with data-driven simulations via logs of Math.StackExchange, a StackOverflow forum dedicated to mathematics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.00674v3},
author = {Shah, Virag and Gulikers, Lennart and Massouli{\'{e}}, Laurent and Vojnovi{\'{c}}, Milan},
booktitle = {2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
doi = {10.1109/ALLERTON.2017.8262814},
eprint = {arXiv:1703.00674v3},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/03-articles/latest/prev-cqa-studies/shah-milan-matching.pdf:pdf},
isbn = {9781538632666},
pages = {753--760},
publisher = {IEEE},
title = {{Adaptive matching for expert systems with uncertain task types}},
year = {2018}
}
@inproceedings{Chiang2010,
abstract = {We describe a Bayesian inference algorithm that can be used to train any cascade of weighted finite-state transducers on end-to-end data. We also investigate the problem of automatically selecting from among mul-tiple training runs. Our experiments on four different tasks demonstrate the genericity of this framework, and, where applicable, large improvements in performance over EM. We also show, for unsupervised part-of-speech tagging, that automatic run selection gives a large improvement over previous Bayesian ap-proaches.},
author = {Chiang, D and Graehl, Jonathan and Knight, Kevin and Pauls, Adam and Ravi, Sujith},
booktitle = {HLT/NAACL},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Chiang et al. - 2010 - Bayesian Inference for Finite-State Transducers.pdf:pdf},
isbn = {1932432655},
pages = {447--455},
title = {{Bayesian Inference for Finite-State Transducers}},
year = {2010}
}
@inproceedings{Allamanis2013,
author = {Allamanis, Miltiadis and Sutton, Charles},
booktitle = {2013 10th Working Conference on Mining Software Repositories (MSR)},
doi = {10.1109/MSR.2013.6624004},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Allamanis, Sutton - 2013 - Why, when, and what Analyzing stack overflow questions by topic, type, and code.pdf:pdf},
isbn = {9781467329361},
issn = {21601852},
pages = {53--56},
publisher = {IEEE},
title = {{Why, when, and what: Analyzing stack overflow questions by topic, type, and code}},
year = {2013}
}
@article{Fligner1986,
author = {Fligner, M. and Verducci, J. S},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Fligner, Verducci - 1986 - Distance based ranking models.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {analysis of covariance,kernel smoothing,partial linear models},
number = {3},
pages = {359--369},
title = {{Distance based ranking models}},
volume = {48},
year = {1986}
}
@inproceedings{Ravi2014,
abstract = {Asking the right question in the right way is an art (and a science). In a community question-answering setting, a good question is not just one that is found to be useful by other people—a question is good if it is also pre-sented clearly and shows prior research. Using a com-munity question-answering site that allows voting over the questions, we show that there is a notion of question quality that goes beyond mere popularity. We present techniques using latent topical models to automatically predict the quality of questions based on their content. Our best system achieves a prediction accuracy of 72{\%}, beating out strong baselines by a significant amount. We also examine the effect of question quality on the dy-namics of user behavior and the longevity of questions.},
author = {Ravi, Sujith and Pang, Bo and Rastogi, V and Kumar, Ravi},
booktitle = {Eighth International AAAI Conference on Weblogs and Social Media},
file = {:Users/brad/Dropbox/lse-msc-thesis-brad/articles/00-final-nb-articles/question-quality/01-great-question-quality-ravi.pdf:pdf},
isbn = {978-1-57735-657-8},
keywords = {Full Papers},
number = {1},
pages = {426--435},
title = {{Great Question! Question Quality in Community Q{\&}A}},
year = {2014}
}
@article{Blei2003,
author = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
file = {:Users/brad/Library/Application Support/Mendeley Desktop/Downloaded/Blei, Ng, Jordan - 2003 - Latent Dirichlet Allocation.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {993--1022},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}
